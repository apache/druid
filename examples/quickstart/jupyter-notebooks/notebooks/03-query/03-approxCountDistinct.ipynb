{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4188e2c5-4ab0-45e3-9371-52d510a97413",
   "metadata": {},
   "source": [
    "# Counting distinct values\n",
    "\n",
    "It's extremely common for analysts to want to count unique occurrences of some result set or function. The Druid database enables you to leverage advanced computer science techniques to speed up this type of calculation through approximation.\n",
    "\n",
    "In this tutorial, work through some examples and see the effect of turning approximation on and off, and of making it even faster by pre-generating the objects that it uses to execute them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e06e8-9b35-4b34-8322-8a8ede6de709",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 26.0.0 or later.\n",
    "\n",
    "#### Run using Docker\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `druid-jupyter` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see [Docker for Jupyter Notebook tutorials](https://druid.apache.org/docs/latest/tutorials/tutorial-jupyter-docker.html).\n",
    "   \n",
    "#### Run without using Docker\n",
    "\n",
    "If you do not use the Docker Compose environment, you need the following:\n",
    "\n",
    "* A running Apache Druid instance, with a `DRUID_HOST` local environment variable containing the server name of your Druid router.\n",
    "* [druidapi](https://github.com/apache/druid/blob/master/examples/quickstart/jupyter-notebooks/druidapi/README.md), a Python client for Apache Druid. Follow the instructions in the Install section of the README file.\n",
    "* [matplotlib](https://matplotlib.org/), a library for creating visualizations in Python.\n",
    "* [pandas](https://pandas.pydata.org/), a data analysis and manipulation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3317c51-627c-4a44-ad73-0860a5f4c937",
   "metadata": {},
   "source": [
    "### Initialize Python\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a19226-6abc-436d-ac3c-9c04d6026707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "    \n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee22cea-6176-4119-b4ea-24ed76cfa8fe",
   "metadata": {},
   "source": [
    "### Load example data\n",
    "\n",
    "Once your Druid environment is up and running, ingest the sample data for this tutorial.\n",
    "\n",
    "Run the following cell to create a table called `example-flights-countdistinct`.  When completed, you'll see a description of the final table.\n",
    "\n",
    "Monitor the ingestion task process in the Druid console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a6366-61e5-4aaf-acab-ad90fbc5a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"example-flights-countdistinct\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (SELECT *\n",
    "FROM TABLE(\n",
    "  EXTERN(\n",
    "    '{\"type\":\"http\",\"uris\":[\"https://static.imply.io/example-data/flight_on_time/flights/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11.csv.zip\"]}',\n",
    "    '{\"type\":\"csv\",\"findColumnsFromHeader\":true}'\n",
    "  )\n",
    ") EXTEND (\"depaturetime\" VARCHAR, \"arrivalime\" VARCHAR, \"Year\" BIGINT, \"Quarter\" BIGINT, \"Month\" BIGINT, \"DayofMonth\" BIGINT, \"DayOfWeek\" BIGINT, \"FlightDate\" VARCHAR, \"Reporting_Airline\" VARCHAR, \"DOT_ID_Reporting_Airline\" BIGINT, \"IATA_CODE_Reporting_Airline\" VARCHAR, \"Tail_Number\" VARCHAR, \"Flight_Number_Reporting_Airline\" BIGINT, \"OriginAirportID\" BIGINT, \"OriginAirportSeqID\" BIGINT, \"OriginCityMarketID\" BIGINT, \"Origin\" VARCHAR, \"OriginCityName\" VARCHAR, \"OriginState\" VARCHAR, \"OriginStateFips\" BIGINT, \"OriginStateName\" VARCHAR, \"OriginWac\" BIGINT, \"DestAirportID\" BIGINT, \"DestAirportSeqID\" BIGINT, \"DestCityMarketID\" BIGINT, \"Dest\" VARCHAR, \"DestCityName\" VARCHAR, \"DestState\" VARCHAR, \"DestStateFips\" BIGINT, \"DestStateName\" VARCHAR, \"DestWac\" BIGINT, \"CRSDepTime\" BIGINT, \"DepTime\" BIGINT, \"DepDelay\" BIGINT, \"DepDelayMinutes\" BIGINT, \"DepDel15\" BIGINT, \"DepartureDelayGroups\" BIGINT, \"DepTimeBlk\" VARCHAR, \"TaxiOut\" BIGINT, \"WheelsOff\" BIGINT, \"WheelsOn\" BIGINT, \"TaxiIn\" BIGINT, \"CRSArrTime\" BIGINT, \"ArrTime\" BIGINT, \"ArrDelay\" BIGINT, \"ArrDelayMinutes\" BIGINT, \"ArrDel15\" BIGINT, \"ArrivalDelayGroups\" BIGINT, \"ArrTimeBlk\" VARCHAR, \"Cancelled\" BIGINT, \"CancellationCode\" VARCHAR, \"Diverted\" BIGINT, \"CRSElapsedTime\" BIGINT, \"ActualElapsedTime\" BIGINT, \"AirTime\" BIGINT, \"Flights\" BIGINT, \"Distance\" BIGINT, \"DistanceGroup\" BIGINT, \"CarrierDelay\" BIGINT, \"WeatherDelay\" BIGINT, \"NASDelay\" BIGINT, \"SecurityDelay\" BIGINT, \"LateAircraftDelay\" BIGINT, \"FirstDepTime\" VARCHAR, \"TotalAddGTime\" VARCHAR, \"LongestAddGTime\" VARCHAR, \"DivAirportLandings\" VARCHAR, \"DivReachedDest\" VARCHAR, \"DivActualElapsedTime\" VARCHAR, \"DivArrDelay\" VARCHAR, \"DivDistance\" VARCHAR, \"Div1Airport\" VARCHAR, \"Div1AirportID\" VARCHAR, \"Div1AirportSeqID\" VARCHAR, \"Div1WheelsOn\" VARCHAR, \"Div1TotalGTime\" VARCHAR, \"Div1LongestGTime\" VARCHAR, \"Div1WheelsOff\" VARCHAR, \"Div1TailNum\" VARCHAR, \"Div2Airport\" VARCHAR, \"Div2AirportID\" VARCHAR, \"Div2AirportSeqID\" VARCHAR, \"Div2WheelsOn\" VARCHAR, \"Div2TotalGTime\" VARCHAR, \"Div2LongestGTime\" VARCHAR, \"Div2WheelsOff\" VARCHAR, \"Div2TailNum\" VARCHAR, \"Div3Airport\" VARCHAR, \"Div3AirportID\" VARCHAR, \"Div3AirportSeqID\" VARCHAR, \"Div3WheelsOn\" VARCHAR, \"Div3TotalGTime\" VARCHAR, \"Div3LongestGTime\" VARCHAR, \"Div3WheelsOff\" VARCHAR, \"Div3TailNum\" VARCHAR, \"Div4Airport\" VARCHAR, \"Div4AirportID\" VARCHAR, \"Div4AirportSeqID\" VARCHAR, \"Div4WheelsOn\" VARCHAR, \"Div4TotalGTime\" VARCHAR, \"Div4LongestGTime\" VARCHAR, \"Div4WheelsOff\" VARCHAR, \"Div4TailNum\" VARCHAR, \"Div5Airport\" VARCHAR, \"Div5AirportID\" VARCHAR, \"Div5AirportSeqID\" VARCHAR, \"Div5WheelsOn\" VARCHAR, \"Div5TotalGTime\" VARCHAR, \"Div5LongestGTime\" VARCHAR, \"Div5WheelsOff\" VARCHAR, \"Div5TailNum\" VARCHAR, \"Unnamed: 109\" VARCHAR))\n",
    "SELECT\n",
    "  TIME_PARSE(\"depaturetime\") AS \"__time\",\n",
    "  \"Reporting_Airline\",\n",
    "  \"Tail_Number\",\n",
    "  \"Origin\"\n",
    "FROM \"ext\"\n",
    "PARTITIONED BY DAY\n",
    "'''\n",
    "\n",
    "sql_client.run_task(sql)\n",
    "sql_client.wait_until_ready('example-flights-countdistinct')\n",
    "display.table('example-flights-countdistinct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d1f7-2f34-44fe-9912-4017ed10893c",
   "metadata": {},
   "source": [
    "Finally, run the following cell to import additional Python modules that you will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfd50d-5ef9-4fd1-8077-bf03758c35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388633f-195b-4381-98cc-7a2f80f48690",
   "metadata": {},
   "source": [
    "## Using COUNT(DISTINCT)\n",
    "\n",
    "Finding the number of distinct elements in a set is very common using `COUNT(DISTINCT)` function. But there are other ways to leverage Druid's massively-parallelised query execution engine to solve this problem, particularly on data sets that contain many tens-of-thousands, perhaps even millions of unique values.\n",
    "\n",
    "In the sections that follow, you will try out:\n",
    "\n",
    "* COUNT(DISTINCT) with and without approximation\n",
    "* Apache Datasketch-based set operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8d8bf-69fa-4266-b171-cb550009e89e",
   "metadata": {},
   "source": [
    "### Run COUNT(DISTINCT) with approximation\n",
    "\n",
    "By default, Apache Druid applies approximation to `COUNT(DISTINCT)` queries, helping interactive data exploration be performant, even with a computationally expensive operations like `COUNT(DISTINCT)`.\n",
    "\n",
    "> Approximations improve scalability, storage, and memory use - at the cost of some error.\n",
    "> \n",
    "> _[Gian Merlino](https://github.com/gianm)_\n",
    "\n",
    "You can look into Druid's [configuration files](https://druid.apache.org/docs/26.0.0/configuration/index.html#sql) to find whether this approach has been left as the default by your system administrators (`druid.sql.planner.useApproximateCountDistinct`) and what approach to approximation will be used (`druid.sql.approxCountDistinct.function`).\n",
    "\n",
    "When approximation is used, intermediate results from each data process are put into a representation called a [data sketch](https://datasketches.apache.org/) - a probabilistic data structure with size not dependent on the underlying data. These are then unioned and the size of the set is estimated.\n",
    "\n",
    "Run the following cell to execute a `COUNT(DISTINCT)` query that, by default, will run using approximation. It finds the number of unique `Tail_Number`s for each `Reporting_Airline` and stores the results in a dataframe. The results are then plotted in a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e5184-9fe4-4f21-a471-4e15d16515c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    \"Reporting_Airline\",\n",
    "    COUNT(DISTINCT \"Tail_Number\") AS \"Unique Tail Numbers\"\n",
    "FROM \"example-flights-countdistinct\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2\n",
    "'''\n",
    "\n",
    "df1 = pd.DataFrame(sql_client.sql(sql))\n",
    "\n",
    "df1.plot.bar(x='Reporting_Airline', y='Unique Tail Numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37d854-efd9-401a-8726-9949bff0c012",
   "metadata": {},
   "source": [
    "### Run COUNT(DISTINCT) without approximation\n",
    "\n",
    "Supply a query context parameter, `useApproximateCountDistinct`, to force Druid to not use approximation for `COUNT(DISTINCT)` queries.\n",
    "\n",
    "Using the same SQL statement as before, the following cell crafts a request (`req`). The request is then given a context parameter to turn off approximation. The response is then stored and put into a second dataframe, from which we get a plot of unique `Tail_Number`s by `Reporting_Airline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652988ac-c256-46d4-a4ea-dbcf0e023991",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"useApproximateCountDistinct\", \"false\")\n",
    "resp = sql_client.sql_query(req)\n",
    "\n",
    "df2 = pd.DataFrame(resp.rows)\n",
    "df2.plot.bar(x='Reporting_Airline', y='Unique Tail Numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c91329-8d05-46eb-8c19-5eaf9043dcb6",
   "metadata": {},
   "source": [
    "### Compare the results\n",
    "\n",
    "The next cell shows a comparison of the two results above: `df1` used the default approximation approach, while `df2` are the results where we turned approximation off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a031f-a805-45dd-935b-d8af808041a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.compare(df2, keep_equal=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3320d-d4ec-460a-b1fc-59c98f85cc3a",
   "metadata": {},
   "source": [
    "The table shows:\n",
    "\n",
    "* A row number\n",
    "* The reporting airline in the approximate results (`self`) versus that in the non-approximate results (`other`)\n",
    "* The calculated distinct number of `Tail Number`s\n",
    "\n",
    "Notice that there are _value_ errors, as you might expect with approximation, and that in some instances this affects the _order_ of results.\n",
    "\n",
    "Error in sketch-based approximation is probabilistic, rather than guaranteed. That's to say that a certain percentage of the time you can expect the measurements you take to be within a certain distance of the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d3cae-1e1d-47d0-9143-91b19d58e17e",
   "metadata": {},
   "source": [
    "## Calculating set union with Theta and HyperLogLog sketches\n",
    "\n",
    "There are two types of Apache Datasketch you can use to estimate the size of a union of one or more sets:\n",
    "\n",
    "* [HyperLogLog](https://druid.apache.org/docs/26.0.0/querying/sql-aggregations.html#hll-sketch-functions)\n",
    "* [Theta](https://druid.apache.org/docs/26.0.0/querying/sql-aggregations.html#theta-sketch-functions)\n",
    "\n",
    "Each allows Druid to estimate the `COUNT(DISTINCT)` of the union of two or more sets. When you ran the `COUNT(DISTINCT)` query in approximate mode, Druid arrived at a single set that was the union of the intermediate sets, and returned an estimate of the set size.\n",
    "\n",
    "In Druid SQL, you can access functions that allow you to define your own sets that you can union in order to estimate their size.\n",
    "\n",
    "Run the next cell, which:\n",
    "\n",
    "* Gets three sets of `Tail_Number`s using `DS_HLL` - it applies a `FILTER` to isolate flights out of three specific cities,\n",
    "* Applies `HLL_SKETCH_UNION` to union the three sets, and\n",
    "* Estimates the resulting set size with `HLL_SKETCH_ESTIMATE`.\n",
    "\n",
    "It uses `TIME_FLOOR` to giving us a week-by-week `GROUP BY` of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be5c57-bb35-4082-87f4-730c2f79621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1W') AS \"Week commencing\",\n",
    "  HLL_SKETCH_ESTIMATE(\n",
    "     HLL_SKETCH_UNION(\n",
    "       DS_HLL(\"Tail_Number\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_HLL(\"Tail_Number\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_HLL(\"Tail_Number\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AnyCity-HLL\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_UNION(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AnyCity-Theta\"\n",
    "FROM \"example-flights-countdistinct\"\n",
    "WHERE TIMESTAMP '2005-10-31' <= __time AND __time <= TIMESTAMP '2005-11-20'\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7463ef-e7db-47be-9dd7-9b3abc84819b",
   "metadata": {},
   "source": [
    "Because of differences in how HyperLogLog and Theta sketch functions themselves work, and defaults of how intermediate sketches themselves are constructed at query-time, there are differences in the results between HyperLogLog and Theta sketches.\n",
    "\n",
    "Read more about this in the [documentation](https://druid.apache.org/docs/26.0.0/querying/sql-aggregations.html#hll-sketch-functions) for the `DS_HLL` and `DS_THETA` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadd455-f558-45c8-92ec-4bdf478d19fb",
   "metadata": {},
   "source": [
    "## Calculating set intersection and difference with Theta sketches\n",
    "\n",
    "With Theta sketches, you can additionally approximate the size of:\n",
    "\n",
    "* The intersection of two sets (airplanes that went to both ATL _and_ SFO)\n",
    "* The difference between one set and another (airplanes that went to ATL and _not_ SFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b746e3c-e29b-410c-8e31-48e66a4e307f",
   "metadata": {},
   "source": [
    "### Set intersection\n",
    "\n",
    "Run the next cell to see the intersection between three Theta sketch sets, week-by-week.\n",
    "\n",
    "As in the query above, each set is filtered to specific airports, then an intersection is performed, before finally the size of that set is estimated and passed back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858e6a2-9d4b-43a5-a458-247357ede7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1W') AS \"Week commencing\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_INTERSECT(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AllThreeCities\"\n",
    "FROM \"example-flights-countdistinct\"\n",
    "WHERE TIMESTAMP '2005-10-31' <= __time AND __time <= TIMESTAMP '2005-11-20'\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db62ec4-3fd6-4cf6-8ea5-1cb55639e30b",
   "metadata": {},
   "source": [
    "This is an important application of set operations: estimating how many of some object carried out some action or other. In the example above, that is how many airplanes took off from from all three cities by week.\n",
    "\n",
    "Another application might be to use Druid's event analytics capabilities to look for time-based intersections.\n",
    "\n",
    "The next cell creates a dataframe from SQL that creates two sets using the `FILTER` function. The first set represents all airplanes that flew on the week commencing 31st October, and the second for the week commencing 7th November. It then intersects these to create a new sketch representing all the airplanes that flew on both days. Finally, the size of that set is estimated, with a `GROUP BY` that breaks it down by `Reporting_Airline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c958d-431f-4aa8-b3b5-8fe2db126757",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  \"Reporting_Airline\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_INTERSECT(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-10-31'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-11-07')\n",
    "      )\n",
    "    ) AS \"BothWeeks\"\n",
    "FROM \"example-flights-countdistinct\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "df = pd.DataFrame(sql_client.sql(sql))\n",
    "\n",
    "df.plot.bar(x='Reporting_Airline', y='BothWeeks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822ea42-2ad5-42fb-aaf3-74747f2e1048",
   "metadata": {},
   "source": [
    "### Set difference\n",
    "\n",
    "Finally, we turn to using Theta sketch operations to estimate the size of the difference between one set and another.\n",
    "\n",
    "The next cell switches the `THETA_SKETCH_INTERSECT` operation, which intersects the sets, for `THETA_SKETCH_NOT`, which does a difference operation. The plot we see therefore charts, approximately, how many airplanes flew in the week commencing 31st October that did _not_ also fly in the next week.\n",
    "\n",
    "Note that this operation is not cumulative - Druid calculates the size of the difference (A to B) per airline: it is not a symmetric difference operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33793dc-cbe4-412e-800c-86d3f57c6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  \"Reporting_Airline\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_NOT(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-10-31'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-11-07')\n",
    "      )\n",
    "    ) AS \"FirstNotSecondWeek\"\n",
    "FROM \"example-flights-countdistinct\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "df = pd.DataFrame(sql_client.sql(sql))\n",
    "\n",
    "df.plot.bar(x='Reporting_Airline', y='FirstNotSecondWeek')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a1846-5072-4495-b840-a620de3c0442",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Approximation is the default execution model for `COUNT(DISTINCT)` queries\n",
    "* You can turn it off with a query context parameter\n",
    "* Accuracy is governed by the size and mode of the data sketch and by the operations you perform.\n",
    "* HyperLogLog and Theta sketches both allow you to approximate `COUNT(DISTINCT)` of entire sets\n",
    "* Only Theta sketches allow you to carry out set operations\n",
    "\n",
    "## Go further\n",
    "\n",
    "* Try estimation on your own dataset:\n",
    "    * Identify a high-cardinality column in one of your own datasets\n",
    "    * Test how long an approximate `DISTINCT(COUNT)` query takes to run with approximation turned on\n",
    "    * Test how long the same query takes to run with approximation turned off\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Read the [Theta sketch](https://druid.apache.org/docs/26.0.0/development/extensions-core/datasketches-theta.html) documentation for reference on ingestion and native queries on Theta sketches in Druid.\n",
    "* Review the [Theta sketch scalar functions](https://druid.apache.org/docs/26.0.0/querying/sql-scalar.html#theta-sketch-functions) and [Theta sketch aggregation functions](https://druid.apache.org/docs/latest/querying/sql-aggregations.html#theta-sketch-functions) documentation.\n",
    "* Read [Sketches for high cardinality columns](https://druid.apache.org/docs/latest/ingestion/schema-design.html#sketches-for-high-cardinality-columns) in the schema design guidance.\n",
    "* Peek at the [DataSketches extension](https://druid.apache.org/docs/latest/development/extensions-core/datasketches-extension.html) documentation for information about other available sketches.\n",
    "* Visit the [Apache Datasketches](https://datasketches.apache.org) project site, where you will also find information on [accuracy](https://datasketches.apache.org/docs/Theta/ThetaAccuracy.html).\n",
    "* Watch [Casting the spell: Apache Druid in practice](https://youtu.be/QAitmv8QRq4) by Itai Yaffe and Yakir Buskilla (Nielsen)\n",
    "* Watch [Employ Approximation](https://youtu.be/il84eH0kUyc) by Peter Marshall (Imply)\n",
    "* Watch [Advertiser audience forecasting with Apache Druid](https://youtu.be/7PRWDMRSAOw) by Qasim Zeeshan and Sundeep Yedida (Reddit)\n",
    "* Watch [Funnel Analysis in Mobile Gaming - leveraging approximation algorithms for low latency analytics](https://youtu.be/il84eH0kUyc) by Ramón Lastres Guerrero (Game Analytics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
