{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4188e2c5-4ab0-45e3-9371-52d510a97413",
   "metadata": {},
   "source": [
    "# Counting distinct values\n",
    "\n",
    "It's extremely common for analysts to want to count unique occurences of some result set or function. The Druid database enables you to leverage advanced computer science techniques to speed up this type of calculation through approximation.\n",
    "\n",
    "In this tutorial, work through some examples and see the effect of turning it on and off, and of making it even faster by pre-generating the objects that Druid uses to execute the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e06e8-9b35-4b34-8322-8a8ede6de709",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 26.0.0 or later.\n",
    "\n",
    "#### Run using Docker\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `druid-jupyter` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see [Docker for Jupyter Notebook tutorials](https://druid.apache.org/docs/latest/tutorials/tutorial-jupyter-docker.html).\n",
    "   \n",
    "#### Run without using Docker\n",
    "\n",
    "If you do not use the Docker Compose environment, you need the following:\n",
    "\n",
    "* A running Apache Druid instance, with a `DRUID_HOST` local environment variable containing the servername of your Druid router\n",
    "* [druidapi](https://github.com/apache/druid/blob/master/examples/quickstart/jupyter-notebooks/druidapi/README.md), a Python client for Apache Druid. Follow the instructions in the Install section of the README file.\n",
    "* [matplotlib](https://matplotlib.org/), a library for creating visualizations in Python,\n",
    "* [pandas](https://pandas.pydata.org/), a data analysis and manipulation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3317c51-627c-4a44-ad73-0860a5f4c937",
   "metadata": {},
   "source": [
    "### Initialize Python\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a19226-6abc-436d-ac3c-9c04d6026707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "    \n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee22cea-6176-4119-b4ea-24ed76cfa8fe",
   "metadata": {},
   "source": [
    "### Load example data\n",
    "\n",
    "Once your Druid environment is up and running, ingest the sample data for this tutorial.\n",
    "\n",
    "Open the Druid console, and ingest the data as follows:\n",
    "\n",
    "1. Select **Load data** from the top-level navigation.\n",
    "2. Select **Batch - SQL**.\n",
    "3. For the input type, select **Example data**.\n",
    "4. Select **FlightCarrierOnTime (1 month)**.\n",
    "5. Click **Use example**.\n",
    "\n",
    "Go through the data loader wizard using the defaults, including the datasource name:\n",
    "\n",
    "`On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11`\n",
    "\n",
    "Run the following cell to describe the table, a handy way to check that the table that you will need for this notebook is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8ca0e-5832-4c5f-88a3-4336ec145958",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.table('On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d1f7-2f34-44fe-9912-4017ed10893c",
   "metadata": {},
   "source": [
    "Finally, run the following cell to import additional Python modules that you will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfd50d-5ef9-4fd1-8077-bf03758c35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388633f-195b-4381-98cc-7a2f80f48690",
   "metadata": {},
   "source": [
    "## Using COUNT(DISTINCT)\n",
    "\n",
    "Finding the number of distinct elements in a set is very common - a `COUNT(DISTINCT)` function, like the one below, allows analysts to determine how many individual things, like a visitor, a device, or an airplane (!), appear in a set. \n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    \"Reporting_Airline\",\n",
    "    COUNT(DISTINCT \"Tail_Number\") AS \"Events\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2\n",
    "```\n",
    "\n",
    "In Druid, each data server computes its own intermediate results that are then merged into a final result set. In a `COUNT(DISTINCT)` query, each process its own set of results, passes these back, and then computation is done to find the result. When the dimension being looked at contains many tens-of-thousands, perhaps even millions of unique values, the transfer of intermediate results and the final computation can be both memory and CPU hungry.\n",
    "\n",
    "During planning, Druid looks for query patterns that benefit from from approximation, like `COUNT(DISTINCT)`. You can therefore handle these types of queries in two modes – with and without [Apache Datasketch](https://datasketches.apache.org/)-based approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8d8bf-69fa-4266-b171-cb550009e89e",
   "metadata": {},
   "source": [
    "### COUNT(DISTINCT) with approximation\n",
    "\n",
    "With approximation, intermediate results from each data process are put into a representation called a [data sketch](https://datasketches.apache.org/). These objects are transfered and merged together as the queries complete. Data sketch size is not dependent on the underlying data – the default size of a sketch in Druid is just over 2000 bytes.\n",
    "\n",
    "This translates into much faster query execution, especially when the intermediate results are large. The most scalable part of Druid – the data processes – do much more of the work, and do so earlier.\n",
    "\n",
    "> Approximations improve scalability, storage, and memory use - at the cost of some error.\n",
    "> \n",
    "> _[Gian Merlino](https://github.com/gianm)_\n",
    "\n",
    "By default, each Druid process will be calculating its local results as data sketches, passing these back for the final merge operation on which size estimation is performed.\n",
    "\n",
    "You can look into Druid's [configuration files](https://druid.apache.org/docs/26.0.0/configuration/index.html#sql) to find whether this approach has been left as the default by your system administrators (`druid.sql.planner.useApproximateCountDistinct`) and what type of data sketch will be used (`druid.sql.approxCountDistinct.function`).\n",
    "\n",
    "Run the following cell to execute a `COUNT(DISTINCT)` query. It finds the number of unique `Tail_Number`s for each `Reporting_Airline` and stores the results in a dataframe. The results are then plotted in a histogram.\n",
    "\n",
    "With default settings, this query will execute using approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e5184-9fe4-4f21-a471-4e15d16515c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    \"Reporting_Airline\",\n",
    "    COUNT(DISTINCT \"Tail_Number\") AS \"Unique Tail Numbers\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2\n",
    "'''\n",
    "\n",
    "df1 = pd.DataFrame(sql_client.sql(sql))\n",
    "\n",
    "df1.plot.bar(x='Reporting_Airline', y='Unique Tail Numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37d854-efd9-401a-8726-9949bff0c012",
   "metadata": {},
   "source": [
    "### COUNT(DISTINCT) without approximation\n",
    "\n",
    "Supply a query context parameter, `useApproximateCountDistinct`, to force Druid to not use approximation for `COUNT(DISTINCT)` queries.\n",
    "\n",
    "Using the same SQL statement as before, the following cell crafts a request (`req`). The request is then given a context parameter to turn off approximation. The response is then stored and put into a second dataframe, from which we get a plot of unique `Tail_Number`s by `Reporting_Airline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652988ac-c256-46d4-a4ea-dbcf0e023991",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"useApproximateCountDistinct\", \"false\")\n",
    "resp = sql_client.sql_query(req)\n",
    "\n",
    "df2 = pd.DataFrame(resp.rows)\n",
    "df2.plot.bar(x='Reporting_Airline', y='Unique Tail Numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c91329-8d05-46eb-8c19-5eaf9043dcb6",
   "metadata": {},
   "source": [
    "### Comparing approximate and non-approximate results\n",
    "\n",
    "The next cell shows a comparison of the two results above: `df1` used the default approximation approach, while `df2` are the results where we turned approximation off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a031f-a805-45dd-935b-d8af808041a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.compare(df2, keep_equal=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3320d-d4ec-460a-b1fc-59c98f85cc3a",
   "metadata": {},
   "source": [
    "The table shows:\n",
    "\n",
    "* A row number\n",
    "* The reporting airline in the approximate results (`self`) versus that in the non-approximate results (`other`)\n",
    "* The calculated distinct number of `Tail Number`s\n",
    "\n",
    "Notice that there are _value_ errors, as you might expect with approximation, and that in some instances this affects the _order_ of results.\n",
    "\n",
    "Error in sketch-based approximation is probabilistic, rather than guaranteed. That's to say that a certain percentage of the time you can expect the measurements you take to be within a certain distance of the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d3cae-1e1d-47d0-9143-91b19d58e17e",
   "metadata": {},
   "source": [
    "## Calculating set union with Theta and HyperLogLog sketches\n",
    "\n",
    "There are two types of Apache Datasketch you can use to estimate the size of a union of one or more sets:\n",
    "\n",
    "* [HyperLogLog](https://druid.apache.org/docs/26.0.0/querying/sql-aggregations.html#hll-sketch-functions)\n",
    "* [Theta](https://druid.apache.org/docs/26.0.0/querying/sql-aggregations.html#theta-sketch-functions)\n",
    "\n",
    "Each allows Druid to estimate the `COUNT(DISTINCT)` of the union of two or more sets. When you ran the `COUNT(DISTINCT)` query in approximate mode, Druid arrived at a single set that was the union of the intermediate sets, and returned an estimate of the set size.\n",
    "\n",
    "In Druid SQL, you can access functions that allow you to define your own sets that you can union in order to estimate their size.\n",
    "\n",
    "Run the next cell, which:\n",
    "\n",
    "* Gets three sets of `Tail_Number`s using `DS_HLL` - it applies a `FILTER` to isolate flights out of three specific cities,\n",
    "* Applies `HLL_SKETCH_UNION` to union the three sets, and\n",
    "* Estimates the resulting set size with `HLL_SKETCH_ESTIMATE`.\n",
    "\n",
    "It uses `TIME_FLOOR` to giving us a week-by-week `GROUP BY` of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be5c57-bb35-4082-87f4-730c2f79621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1W') AS \"Week commencing\",\n",
    "  HLL_SKETCH_ESTIMATE(\n",
    "     HLL_SKETCH_UNION(\n",
    "       DS_HLL(\"Tail_Number\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_HLL(\"Tail_Number\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_HLL(\"Tail_Number\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AnyCity-HLL\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_UNION(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AnyCity-Theta\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "WHERE TIMESTAMP '2005-10-31' <= __time AND __time <= TIMESTAMP '2005-11-20'\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7463ef-e7db-47be-9dd7-9b3abc84819b",
   "metadata": {},
   "source": [
    "Because of differences in how HyperLogLog and Theta sketch functions themselves work, and defaults of how intermediate sketches themselves are constructed at query-time, there are differences in the results between HyperLogLog and Theta sketches.\n",
    "\n",
    "Read more about this in the [documentation](https://druid.apache.org/docs/26.0.0/querying/sql-aggregations.html#hll-sketch-functions) for the `DS_HLL` and `DS_THETA` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadd455-f558-45c8-92ec-4bdf478d19fb",
   "metadata": {},
   "source": [
    "## Calculating set intersection and difference with Theta sketches\n",
    "\n",
    "With Theta sketches, you can also approximate the size of:\n",
    "\n",
    "* The intersection of two sets (airplanes that went to both ATL _and_ SFO)\n",
    "* The difference between one set and another (airplanes that went to ATL and _not_ SFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b746e3c-e29b-410c-8e31-48e66a4e307f",
   "metadata": {},
   "source": [
    "### Set intersection\n",
    "\n",
    "Run the next cell to see the intersection between three Theta sketch sets, week-by-week.\n",
    "\n",
    "As in the query above, each set is filtered to specific airports, then an intersection is performed, before finally the size of that set is estimated and passed back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858e6a2-9d4b-43a5-a458-247357ede7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1W') AS \"Week commencing\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_INTERSECT(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AllThreeCities\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "WHERE TIMESTAMP '2005-10-31' <= __time AND __time <= TIMESTAMP '2005-11-20'\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db62ec4-3fd6-4cf6-8ea5-1cb55639e30b",
   "metadata": {},
   "source": [
    "This is an important application of set operations: estimating how many of some object carried out some action or other. In the example above, that is how many airplanes took off from from all three cities by week.\n",
    "\n",
    "Another application might be to use Druid's event analytics capabilities to look for time-based intersections.\n",
    "\n",
    "The next cell creates a dataframe from SQL that creates two sets using the `FILTER` function. The first set represents all airplanes that flew on the week commencing 31st October, and the second for the week commencing 7th November. It then intersects these to create a new sketch representing all the airplanes that flew on both days. Finally, the size of that set is estimated, with a `GROUP BY` that breaks it down by `Reporting_Airline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c958d-431f-4aa8-b3b5-8fe2db126757",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  \"Reporting_Airline\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_INTERSECT(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-10-31'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-11-07')\n",
    "      )\n",
    "    ) AS \"BothWeeks\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "df = pd.DataFrame(sql_client.sql(sql))\n",
    "\n",
    "df.plot.bar(x='Reporting_Airline', y='BothWeeks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822ea42-2ad5-42fb-aaf3-74747f2e1048",
   "metadata": {},
   "source": [
    "### Set difference\n",
    "\n",
    "Finally, we turn to using Theta sketch operations to estimate the size of the difference between one set and another.\n",
    "\n",
    "The next cell switches the `THETA_SKETCH_INTERSECT` operation, which intersects the sets, for `THETA_SKETCH_NOT`, which does a difference operation. The plot we see therefore charts, approximately, how many airplanes flew in the week commencing 31st October that did _not_ also fly in the next weeek.\n",
    "\n",
    "Note that this operation is not cumutative - Druid calculates the size of the difference (A to B) per airline: it is not a symetric difference operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33793dc-cbe4-412e-800c-86d3f57c6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  \"Reporting_Airline\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_NOT(\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-10-31'),\n",
    "       DS_THETA(\"Tail_Number\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-11-07')\n",
    "      )\n",
    "    ) AS \"FirstNotSecondWeek\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "df = pd.DataFrame(sql_client.sql(sql))\n",
    "\n",
    "df.plot.bar(x='Reporting_Airline', y='FirstNotSecondWeek')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a1846-5072-4495-b840-a620de3c0442",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* Approximation is the default execution model for `COUNT(DISTINCT)` queries\n",
    "* You can turn it off with a query context parameter\n",
    "* Accuracy is highly dependent on the distribution and cardinality of data across the database\n",
    "* HyperLogLog and Theta sketches both allow you to approximate `COUNT(DISTINCT)` of entire sets\n",
    "* Only Theta sketches allow you to carry out set operations\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Try estimation on your own dataset:\n",
    "    * Identify a high-cardinality column in one of your own data sets\n",
    "    * Test how long an approximate `DISTINCT(COUNT)` query takes to run with approximation turned on\n",
    "    * Test how long the same query takes to run with approximation turned off\n",
    "* Watch [Casting the spell: Apache Druid in practice](https://youtu.be/QAitmv8QRq4) by Itai Yaffe and Yakir Buskilla (Nielsen)\n",
    "* Watch [Employ Approximation](https://youtu.be/il84eH0kUyc) by Peter Marshall (Imply)\n",
    "* Watch [Advertiser audience forecasting with Apache Druid](https://youtu.be/7PRWDMRSAOw) by Qasim Zeeshan and Sundeep Yedida (Reddit)\n",
    "* Watch [Funnel Analysis in Mobile Gaming - leveraging approximation algorithms for low latency analytics](https://youtu.be/il84eH0kUyc) by Ramón Lastres Guerrero (Game Analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71235a-aa0e-4221-bbee-75c1fd6bafc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
