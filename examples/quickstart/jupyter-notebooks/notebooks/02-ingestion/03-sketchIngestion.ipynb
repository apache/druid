{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4188e2c5-4ab0-45e3-9371-52d510a97413",
   "metadata": {},
   "source": [
    "# Generating Apache Datasketches at ingestion time\n",
    "\n",
    "It's extremely common for analysts to want to count unique occurences of some dimension value in data. With the Druid database's history of large volumes of data comes an advanced computer science technique to speed up this calculation through Apache Datasketches-based approximation.\n",
    "\n",
    "Further speed boost can be achieved by storing sketches inside `TABLE`s directly, making query execution for `COUNT(DISTINCT)` operations leaner and more efficient.\n",
    "\n",
    "In this tutorial, work through generating both HyperLogLog and Theta sketch objects as part of an ingestion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e06e8-9b35-4b34-8322-8a8ede6de709",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 26.0.0 or later.\n",
    "\n",
    "#### Run using Docker\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `druid-jupyter` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see [Docker for Jupyter Notebook tutorials](https://druid.apache.org/docs/latest/tutorials/tutorial-jupyter-docker.html).\n",
    "   \n",
    "#### Run without using Docker\n",
    "\n",
    "If you do not use the Docker Compose environment, you need the following:\n",
    "\n",
    "* A running Apache Druid instance, with a `DRUID_HOST` local environment variable containing the server name of your Druid router.\n",
    "* [druidapi](https://github.com/apache/druid/blob/master/examples/quickstart/jupyter-notebooks/druidapi/README.md), a Python client for Apache Druid. Follow the instructions in the Install section of the README file.\n",
    "* [matplotlib](https://matplotlib.org/), a library for creating visualizations in Python.\n",
    "* [pandas](https://pandas.pydata.org/), a data analysis and manipulation tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3317c51-627c-4a44-ad73-0860a5f4c937",
   "metadata": {},
   "source": [
    "### Initialize Python\n",
    "\n",
    "Run the next cell to set up the Druid Python client's connection to Apache Druid.\n",
    "\n",
    "If successful, the Druid version number will be shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a19226-6abc-436d-ac3c-9c04d6026707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import druidapi\n",
    "import os\n",
    "\n",
    "if 'DRUID_HOST' not in os.environ.keys():\n",
    "    druid_host=f\"http://localhost:8888\"\n",
    "else:\n",
    "    druid_host=f\"http://{os.environ['DRUID_HOST']}:8888\"\n",
    "    \n",
    "print(f\"Opening a connection to {druid_host}.\")\n",
    "druid = druidapi.jupyter_client(druid_host)\n",
    "\n",
    "display = druid.display\n",
    "sql_client = druid.sql\n",
    "status_client = druid.status\n",
    "\n",
    "status_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0d1f7-2f34-44fe-9912-4017ed10893c",
   "metadata": {},
   "source": [
    "Finally, run the following cell to import additional Python modules that you will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfd50d-5ef9-4fd1-8077-bf03758c35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff80c4-8ca6-4563-b67e-70b09a611877",
   "metadata": {},
   "source": [
    "## Generating sketch objects with SQL\n",
    "\n",
    "Run the next cell to get an indication of what a sketch object looks like.\n",
    "\n",
    "It applies a `GROUP BY` to `Reporting_Airline` and uses the [`DS_HLL`](https://druid.apache.org/docs/26.0.0/querying/sql-functions.html#ds_hll) function to create sets of `Tail_Number`s inside a \"HyperLogLog\" sketch object.\n",
    "\n",
    "The results show, for each `Reporting_Airline`, the highly optimized, aggregated list of the `Tail_Number`s.\n",
    "\n",
    "Instead of Druid calculating these with every query, this notebook will walk through storing these in a table and addressing them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595eec0-a709-4cd6-985e-eec8a6e37b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    \"Reporting_Airline\",\n",
    "    DS_HLL(\"Tail_Number\") AS \"Sketch\"\n",
    "FROM \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11\"\n",
    "GROUP BY 1\n",
    "LIMIT 5\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13e4b5-9a8c-4519-9469-27a1518caa9a",
   "metadata": {},
   "source": [
    "### Creating sketches during batch ingestion\n",
    "\n",
    "The next cell incorporates the `DS_HLL` function above into a `REPLACE` statement to build a new table, `flights-counts`.\n",
    "\n",
    "As with the previous SQL, `GROUP BY` is the key to creating an aggregated list of values to go into the sets represented by the sketches. In addition to `Reporting_Airline`, however, we add `Origin`, and `Dest`. And because we need to have a `__time` field, the sets are also broken down by hour using a `TIME_FLOOR` function.\n",
    "\n",
    "Notice that the SQL does not `SELECT` the original `Tail_Number`s. If we kept that field, the `GROUP BY` wouldn't aggregate any rows into the sketch - there would be a 1:1 relationship between the row and each `Tail_Number` - which is the opposite of what we are designing for! By implication, it will be no longer possible to use the raw data as part of any SQL queries, like a `GROUP BY` or a `WHERE`.\n",
    "\n",
    "You will also spot a [`DS_THETA`](https://druid.apache.org/docs/26.0.0/querying/sql-functions.html#ds_theta) function, giving the ability to do intersection and difference operations in addition to unions.\n",
    "\n",
    "Run this cell to store the ingestion SQL into the `sql` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8459462-e0ff-4005-9455-aa7d06a7f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "REPLACE INTO \"flights-counts\" OVERWRITE ALL\n",
    "WITH \"ext\" AS (SELECT *\n",
    "FROM TABLE(\n",
    "  EXTERN(\n",
    "    '{\"type\":\"http\",\"uris\":[\"https://static.imply.io/example-data/flight_on_time/flights/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2005_11.csv.zip\"]}',\n",
    "    '{\"type\":\"csv\",\"findColumnsFromHeader\":true}'\n",
    "  )\n",
    ") EXTEND (\"depaturetime\" VARCHAR, \"arrivalime\" VARCHAR, \"Year\" BIGINT, \"Quarter\" BIGINT, \"Month\" BIGINT, \"DayofMonth\" BIGINT, \"DayOfWeek\" BIGINT, \"FlightDate\" VARCHAR, \"Reporting_Airline\" VARCHAR, \"DOT_ID_Reporting_Airline\" BIGINT, \"IATA_CODE_Reporting_Airline\" VARCHAR, \"Tail_Number\" VARCHAR, \"Flight_Number_Reporting_Airline\" BIGINT, \"OriginAirportID\" BIGINT, \"OriginAirportSeqID\" BIGINT, \"OriginCityMarketID\" BIGINT, \"Origin\" VARCHAR, \"OriginCityName\" VARCHAR, \"OriginState\" VARCHAR, \"OriginStateFips\" BIGINT, \"OriginStateName\" VARCHAR, \"OriginWac\" BIGINT, \"DestAirportID\" BIGINT, \"DestAirportSeqID\" BIGINT, \"DestCityMarketID\" BIGINT, \"Dest\" VARCHAR, \"DestCityName\" VARCHAR, \"DestState\" VARCHAR, \"DestStateFips\" BIGINT, \"DestStateName\" VARCHAR, \"DestWac\" BIGINT, \"CRSDepTime\" BIGINT, \"DepTime\" BIGINT, \"DepDelay\" BIGINT, \"DepDelayMinutes\" BIGINT, \"DepDel15\" BIGINT, \"DepartureDelayGroups\" BIGINT, \"DepTimeBlk\" VARCHAR, \"TaxiOut\" BIGINT, \"WheelsOff\" BIGINT, \"WheelsOn\" BIGINT, \"TaxiIn\" BIGINT, \"CRSArrTime\" BIGINT, \"ArrTime\" BIGINT, \"ArrDelay\" BIGINT, \"ArrDelayMinutes\" BIGINT, \"ArrDel15\" BIGINT, \"ArrivalDelayGroups\" BIGINT, \"ArrTimeBlk\" VARCHAR, \"Cancelled\" BIGINT, \"CancellationCode\" VARCHAR, \"Diverted\" BIGINT, \"CRSElapsedTime\" BIGINT, \"ActualElapsedTime\" BIGINT, \"AirTime\" BIGINT, \"Flights\" BIGINT, \"Distance\" BIGINT, \"DistanceGroup\" BIGINT, \"CarrierDelay\" BIGINT, \"WeatherDelay\" BIGINT, \"NASDelay\" BIGINT, \"SecurityDelay\" BIGINT, \"LateAircraftDelay\" BIGINT, \"FirstDepTime\" VARCHAR, \"TotalAddGTime\" VARCHAR, \"LongestAddGTime\" VARCHAR, \"DivAirportLandings\" VARCHAR, \"DivReachedDest\" VARCHAR, \"DivActualElapsedTime\" VARCHAR, \"DivArrDelay\" VARCHAR, \"DivDistance\" VARCHAR, \"Div1Airport\" VARCHAR, \"Div1AirportID\" VARCHAR, \"Div1AirportSeqID\" VARCHAR, \"Div1WheelsOn\" VARCHAR, \"Div1TotalGTime\" VARCHAR, \"Div1LongestGTime\" VARCHAR, \"Div1WheelsOff\" VARCHAR, \"Div1TailNum\" VARCHAR, \"Div2Airport\" VARCHAR, \"Div2AirportID\" VARCHAR, \"Div2AirportSeqID\" VARCHAR, \"Div2WheelsOn\" VARCHAR, \"Div2TotalGTime\" VARCHAR, \"Div2LongestGTime\" VARCHAR, \"Div2WheelsOff\" VARCHAR, \"Div2TailNum\" VARCHAR, \"Div3Airport\" VARCHAR, \"Div3AirportID\" VARCHAR, \"Div3AirportSeqID\" VARCHAR, \"Div3WheelsOn\" VARCHAR, \"Div3TotalGTime\" VARCHAR, \"Div3LongestGTime\" VARCHAR, \"Div3WheelsOff\" VARCHAR, \"Div3TailNum\" VARCHAR, \"Div4Airport\" VARCHAR, \"Div4AirportID\" VARCHAR, \"Div4AirportSeqID\" VARCHAR, \"Div4WheelsOn\" VARCHAR, \"Div4TotalGTime\" VARCHAR, \"Div4LongestGTime\" VARCHAR, \"Div4WheelsOff\" VARCHAR, \"Div4TailNum\" VARCHAR, \"Div5Airport\" VARCHAR, \"Div5AirportID\" VARCHAR, \"Div5AirportSeqID\" VARCHAR, \"Div5WheelsOn\" VARCHAR, \"Div5TotalGTime\" VARCHAR, \"Div5LongestGTime\" VARCHAR, \"Div5WheelsOff\" VARCHAR, \"Div5TailNum\" VARCHAR, \"Unnamed: 109\" VARCHAR))\n",
    "SELECT\n",
    "  TIME_FLOOR(TIME_PARSE(\"depaturetime\"), 'PT1H') AS \"__time\",\n",
    "  \"Reporting_Airline\",\n",
    "  \"Origin\",\n",
    "  \"Dest\",\n",
    "  COUNT(*) AS \"Events\",\n",
    "  MAX(\"Distance\") AS \"Distance_Max\",\n",
    "  MIN(\"Distance\") AS \"Distance_Min\",\n",
    "  DS_HLL(\"Tail_Number\") AS \"Tail_Number_HLL\",\n",
    "  DS_THETA(\"Tail_Number\") AS \"Tail_Number_THETA\"\n",
    "FROM \"ext\"\n",
    "GROUP BY 1, 2, 3, 4\n",
    "PARTITIONED BY DAY\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586d0f1-e2e4-498b-a98e-1aaa00b65a58",
   "metadata": {},
   "source": [
    "A specific context parameter must be used when creating sketches at ingestion time: [`finalizeAggregations`](https://druid.apache.org/docs/26.0.0/multi-stage-query/reference.html#context-parameters). This prompts Druid to store the true sketch value, and is applied for you automatically when you use the Druid console.\n",
    "\n",
    "As we are running the ingestion programmatically, we must construct a request (`req`) with the appropriate context parameters before we execute the ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58a332-4f86-4d24-a4b6-286b3c4fe54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = sql_client.sql_request(sql)\n",
    "req.add_context(\"finalize\", \"false\")\n",
    "req.add_context(\"finalizeAggregations\", \"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142302a-cfa8-4340-a984-558e8b53c826",
   "metadata": {},
   "source": [
    "Run the following cell to start the ingestion. Monitor the ingestion task itself in the Druid Console as it runs.\n",
    "\n",
    "Once finished, you will see the table definition, including the two sketch dimensions - `Tail_Number_HLL` and `Tail_Number_THETA`. You'll notice that these two dimensions have a `COMPLEX` type, indicating that they are for storing Datasketch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77531983-66b2-48b7-a6d4-d7b7193df360",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_client.run_task(req)\n",
    "sql_client.wait_until_ready('flights-counts')\n",
    "display.table('flights-counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bc114-17a1-4e65-bb47-a8b47469fff6",
   "metadata": {},
   "source": [
    "### Creating sketches during streaming ingestion\n",
    "\n",
    "In streaming ingestion, rather than using `DS_HLL` or `DS_THETA` you include the Druid Native equivallent in the [`metricsSpec`](https://druid.apache.org/docs/26.0.0/ingestion/ingestion-spec.html#metricsspec) and - instead of `GROUP BY` - enable [`queryGranularity`](https://druid.apache.org/docs/latest/ingestion/ingestion-spec.html#granularityspec) and `rollup` to truncate the time stamp and pre-aggregate the rows.\n",
    "\n",
    "The `INSERT` statement above is therefore equivallent to:\n",
    "\n",
    "```json\n",
    "    {\n",
    "      \"type\": \"HLLSketchBuild\",\n",
    "      \"fieldName\": \"Tail_Number\",\n",
    "      \"lgK\": 12,\n",
    "      \"tgtHllType\": \"HLL_4\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"thetaSketch\",\n",
    "      \"fieldName\": \"Tail_Number\",\n",
    "      \"size\": 16384\n",
    "    }\n",
    "```\n",
    "\n",
    "For the purpose of this notebook, we will use the `TABLE` that you have ingested above in batch mode.\n",
    "\n",
    "Notice that here it's easy to see some internal parameters for sketch generation, like the `lgK` value for HLL. In SQL mode, these are exposed as supplementary parameters to the `DS_HLL` function. Be cautious of changing these values without researching the effects - not just in accuracy but also in terms of performance and segment size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e87cea-86df-4ff7-8a5c-8bbb74716aa8",
   "metadata": {},
   "source": [
    "## Using COUNT(DISTINCT) on stored sketches\n",
    "\n",
    "Use specific SQL functions when carrying out `COUNT(DISTINCT)` operations on raw sketches.\n",
    "\n",
    "* For HLL [`APPROX_COUNT_DISTINCT_DS_HLL`](https://druid.apache.org/docs/26.0.0/querying/sql-functions.html#approx_count_distinct_ds_hll), and\n",
    "* for Theta [`APPROX_COUNT_DISTINCT_THETA`](https://druid.apache.org/docs/26.0.0/querying/sql-functions.html#approx_count_distinct_ds_theta).\n",
    "\n",
    "The following cell estimates the number of unique airplanes over a specific time period using both the HyperLogLog and Theta sketch objects in the `TABLE` that you just created. It breaks it down by `Reporting_Airline` and also includes a `SUM` of the miles flown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4a293-b967-46e1-9a37-7856ce25f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "   \"Reporting_Airline\",\n",
    "   SUM(\"Distance_Max\") AS \"Miles_Flown\",\n",
    "   APPROX_COUNT_DISTINCT_DS_HLL(\"Tail_Number_HLL\") AS \"HLLApprox\",\n",
    "   APPROX_COUNT_DISTINCT_DS_THETA(\"Tail_Number_THETA\") AS \"ThetaApprox\"\n",
    "FROM \"flights-counts\"\n",
    "WHERE TIMESTAMP '2005-10-31' <= __time AND __time <= TIMESTAMP '2005-11-20'\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d3cae-1e1d-47d0-9143-91b19d58e17e",
   "metadata": {},
   "source": [
    "## Calculating set union with stored sketches\n",
    "\n",
    "Using stored sketches as part of a union operation is very similar to when they have not been stored. The difference being that you address the sketch directly in the `DS_HLL` function, rather than the raw data.\n",
    "\n",
    "Run next cell, which:\n",
    "\n",
    "* Constructs three sets, each represented as a HyperLogLog sketch, using `DS_HLL` against the stored `Tail_Number_HLL` sketches - it also applies a `FILTER` to isolate flights out of three specific cities,\n",
    "* Applies `HLL_SKETCH_UNION` to union the three sets, and\n",
    "* Estimates the resulting set size with `HLL_SKETCH_ESTIMATE`.\n",
    "\n",
    "It also includes the same operation using Theta sketches. Again, three sets are created from the underlying sketch data that is then unioned and its size estimated.\n",
    "\n",
    "It uses `TIME_FLOOR` to give a week-by-week `GROUP BY` of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be5c57-bb35-4082-87f4-730c2f79621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\",'P1W') AS \"Week commencing\",\n",
    "  HLL_SKETCH_ESTIMATE(\n",
    "     HLL_SKETCH_UNION(\n",
    "       DS_HLL(\"Tail_Number_HLL\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_HLL(\"Tail_Number_HLL\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_HLL(\"Tail_Number_HLL\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AnyThreeCity-HLL\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_UNION(\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE \"Origin\"='ATL'),\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE \"Origin\"='DFW'),\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE \"Origin\"='SFO')\n",
    "      )\n",
    "    ) AS \"AnyThreeCity-THETA\"\n",
    "FROM \"flights-counts\"\n",
    "WHERE TIMESTAMP '2005-10-31' <= __time AND __time <= TIMESTAMP '2005-11-20'\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadd455-f558-45c8-92ec-4bdf478d19fb",
   "metadata": {},
   "source": [
    "## Calculating set intersection and difference with pre-existing Theta sketches\n",
    "\n",
    "The same techqnieus applies to intersection and difference operations on stored sketches as it does to using raw data, with the difference being the dimension upon which sets are created through `DS_THETA`.\n",
    "\n",
    "Run the following cell, which uses the stored Theta sketch to perform both a difference and an intersection operation on two sets of airplanes, one from the week commencing 31st October, and another for the week commencing 7th November."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858e6a2-9d4b-43a5-a458-247357ede7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql='''\n",
    "SELECT\n",
    "  \"Reporting_Airline\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_NOT(\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-10-31'),\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-11-07')\n",
    "      )\n",
    "    ) AS \"WeekOneNotTwo\",\n",
    "  THETA_SKETCH_ESTIMATE(\n",
    "     THETA_SKETCH_INTERSECT(\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-10-31'),\n",
    "       DS_THETA(\"Tail_Number_THETA\") FILTER (WHERE TIME_FLOOR(\"__time\",'P1W') = TIMESTAMP '2005-11-07')\n",
    "      )\n",
    "    ) AS \"WeekOneAndTwo\"\n",
    "FROM \"flights-counts\"\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "display.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a1846-5072-4495-b840-a620de3c0442",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* Druid can be pre-loaded with sketch objects that speed up approximation both in batch and streaming ingestion\n",
    "* Specific SQL functions are used to address the sketch for `COUNT(DISTINCT)` operations\n",
    "\n",
    "## Learn more\n",
    "\n",
    "* Watch [Employ Approximation](https://youtu.be/fSWwJs1gCvQ?list=PLDZysOZKycN7MZvNxQk_6RbwSJqjSrsNR) by Peter Marshall\n",
    "* Read [Ingesting Data Sketches into Apache Druid](https://blog.hellmar-becker.de/2022/12/26/ingesting-data-sketches-into-apache-druid/) by Hellmar Becker\n",
    "* Read more about the native \"aggregator\" functions for streaming ingestion\n",
    "    * [ThetaSketch function](https://druid.apache.org/docs/26.0.0/development/extensions-core/datasketches-theta.html)\n",
    "    * [HyperLogLog function](https://druid.apache.org/docs/26.0.0/development/extensions-core/datasketches-hll.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71235a-aa0e-4221-bbee-75c1fd6bafc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
