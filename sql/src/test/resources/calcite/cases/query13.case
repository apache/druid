Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
==============================================================
Converted from testRequireTimeConditionPositive()

Simple timeseries
=== case
Require time condition positive (1)
=== SQL
SELECT SUM(cnt), gran FROM (
  SELECT __time as t, floor(__time TO month) AS gran,
  cnt FROM druid.foo
  ) AS x
WHERE t >= '2000-01-01'
  and t < '2002-01-01'
GROUP BY gran
ORDER BY gran
=== options
planner.requireTimeCondition=true
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
gran TIMESTAMP(3)
=== plan
LogicalSort(sort0=[$1], dir0=[ASC])
  LogicalProject(EXPR$0=[$1], gran=[$0])
    LogicalAggregate(group=[{0}], EXPR$0=[SUM($1)])
      LogicalProject(gran=[$1], cnt=[$2])
        LogicalFilter(condition=[AND(>=($0, CAST('2000-01-01'):TIMESTAMP(3) NOT NULL), <($0, CAST('2002-01-01'):TIMESTAMP(3) NOT NULL))])
          LogicalProject(t=[$0], gran=[FLOOR($0, FLAG(MONTH))], cnt=[$1])
            LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "2000-01-01T00:00:00.000Z/2002-01-01T00:00:00.000Z" ]
  },
  "granularity" : "MONTH",
  "aggregations" : [ {
    "type" : "longSum",
    "name" : "a0",
    "fieldName" : "cnt"
  } ],
  "context" : {
    "skipEmptyBuckets" : true,
    "timestampResultField" : "d0"
  }
}
=== results
[3,946684800000]
[3,978307200000]
==============================================================
Converted from testRequireTimeConditionPositive()

Nested GROUP BY only requires time condition for inner most query.
=== case
Require time condition positive
=== SQL
SELECT
  SUM(cnt),
  COUNT(*)
FROM (
  SELECT dim2, SUM(cnt) AS cnt
  FROM druid.foo
  WHERE __time >= '2000-01-01'
  GROUP BY dim2
  )
=== options
planner.requireTimeCondition=true
vectorize=true
=== schema
EXPR$0 BIGINT
EXPR$1 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[SUM($0)], EXPR$1=[COUNT()])
  LogicalProject(cnt=[$1])
    LogicalAggregate(group=[{0}], cnt=[SUM($1)])
      LogicalProject(dim2=[$3], cnt=[$1])
        LogicalFilter(condition=[>=($0, CAST('2000-01-01'):TIMESTAMP(3) NOT NULL)])
          LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "query",
    "query" : {
      "queryType" : "groupBy",
      "dataSource" : {
        "type" : "table",
        "name" : "foo"
      },
      "intervals" : {
        "type" : "intervals",
        "intervals" : [ "2000-01-01T00:00:00.000Z/146140482-04-24T15:36:27.903Z" ]
      },
      "granularity" : {
        "type" : "all"
      },
      "dimensions" : [ {
        "type" : "default",
        "dimension" : "dim2",
        "outputName" : "d0",
        "outputType" : "STRING"
      } ],
      "aggregations" : [ {
        "type" : "longSum",
        "name" : "a0",
        "fieldName" : "cnt"
      } ],
      "limitSpec" : {
        "type" : "NoopLimitSpec"
      }
    }
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ ],
  "aggregations" : [ {
    "type" : "longSum",
    "name" : "_a0",
    "fieldName" : "a0"
  }, {
    "type" : "count",
    "name" : "_a1"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== run
=== options
sqlCompatibleNulls=false
=== results
[6,3]
=== run
=== options
sqlCompatibleNulls=true
=== results
[6,4]
==============================================================
Converted from testRequireTimeConditionPositive()

Cannot vectorize next test due to extraction dimension spec.
Semi-join requires time condition on both left and right query
=== case
Require time condition positive
=== SQL
SELECT COUNT(*) FROM druid.foo
WHERE __time >= '2000-01-01' AND SUBSTRING(dim2, 1, 1) IN (
  SELECT SUBSTRING(dim1, 1, 1) FROM druid.foo
  WHERE dim1 <> '' AND __time >= '2000-01-01'
)
=== options
planner.requireTimeCondition=true
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[AND(>=($0, CAST('2000-01-01'):TIMESTAMP(3) NOT NULL), IN(SUBSTRING($3, 1, 1), {
LogicalProject(EXPR$0=[SUBSTRING($2, 1, 1)])
  LogicalFilter(condition=[AND(<>($2, ''), >=($0, CAST('2000-01-01'):TIMESTAMP(3) NOT NULL))])
    LogicalTableScan(table=[[druid, foo]])
}))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "join",
    "left" : {
      "type" : "table",
      "name" : "foo"
    },
    "right" : {
      "type" : "query",
      "query" : {
        "queryType" : "groupBy",
        "dataSource" : {
          "type" : "table",
          "name" : "foo"
        },
        "intervals" : {
          "type" : "intervals",
          "intervals" : [ "2000-01-01T00:00:00.000Z/146140482-04-24T15:36:27.903Z" ]
        },
        "filter" : {
          "type" : "not",
          "field" : {
            "type" : "selector",
            "dimension" : "dim1",
            "value" : null
          }
        },
        "granularity" : {
          "type" : "all"
        },
        "dimensions" : [ {
          "type" : "extraction",
          "dimension" : "dim1",
          "outputName" : "d0",
          "outputType" : "STRING",
          "extractionFn" : {
            "type" : "substring",
            "index" : 0,
            "length" : 1
          }
        } ],
        "limitSpec" : {
          "type" : "NoopLimitSpec"
        }
      }
    },
    "rightPrefix" : "j0.",
    "condition" : "(substring(\"dim2\", 0, 1) == \"j0.d0\")",
    "joinType" : "INNER"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "2000-01-01T00:00:00.000Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
=== results
[3]
==============================================================
Converted from testRequireTimeConditionLogicalValuePositive()
=== case
Require time condition logical value positive
=== SQL
SELECT 2 + 2 AS a
=== options
planner.requireTimeCondition=true
sqlCompatibleNulls=both
vectorize=true
=== schema
a INTEGER
=== plan
LogicalProject(a=[+(2, 2)])
  LogicalValues(type=[RecordType(INTEGER ZERO)], tuples=[[{ 0 }]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "inline",
    "columnNames" : [ "a" ],
    "columnTypes" : [ "LONG" ],
    "rows" : [ [ 4 ] ]
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "resultFormat" : "compactedList",
  "columns" : [ "a" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
[4]
==============================================================
Converted from testRequireTimeConditionSimpleQueryNegative()

Note that this error could be detected during planning. However,
we perform the check only in the step where we run the query.
This is a semi-bug that should be fixed: do the check at plan
time, not run time.
=== case
Require time condition simple query negative
=== SQL
SELECT SUM(cnt), gran FROM (
  SELECT __time as t, floor(__time TO month) AS gran,
  cnt FROM druid.foo
) AS x
GROUP BY gran
ORDER BY gran
=== options
planner.requireTimeCondition=true
vectorize=true
=== run
=== exception
CannotBuildQueryException
=== error
requireTimeCondition is enabled, all queries must include a filter condition on the __time column
==============================================================
Converted from testRequireTimeConditionSubQueryNegative()
=== case
Require time condition sub query negative
=== SQL
SELECT
  SUM(cnt),
  COUNT(*)
FROM (SELECT dim2, SUM(cnt) AS cnt FROM druid.foo GROUP BY dim2)
=== options
planner.requireTimeCondition=true
vectorize=true
=== run
=== exception
CannotBuildQueryException
=== error
requireTimeCondition is enabled, all queries must include a filter condition on the __time column
==============================================================
Converted from testRequireTimeConditionSemiJoinNegative()
=== case
Require time condition semi join negative
=== SQL
SELECT COUNT(*) FROM druid.foo
WHERE SUBSTRING(dim2, 1, 1) IN (
  SELECT SUBSTRING(dim1, 1, 1) FROM druid.foo
  WHERE dim1 <> '' AND __time >= '2000-01-01'
)
=== options
planner.requireTimeCondition=true
=== exception
CannotBuildQueryException
=== error
requireTimeCondition is enabled, all queries must include a filter condition on the __time column
==============================================================
Converted from testFilterFloatDimension()
=== case
Filter float dimension
=== SQL
SELECT dim1 FROM numfoo WHERE f1 = 0.1 LIMIT 1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
=== plan
LogicalSort(fetch=[1])
  LogicalProject(dim1=[$4])
    LogicalFilter(condition=[=(CAST($10):DOUBLE NOT NULL, 0.1)])
      LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "resultFormat" : "compactedList",
  "limit" : 1,
  "filter" : {
    "type" : "selector",
    "dimension" : "f1",
    "value" : "0.1"
  },
  "columns" : [ "dim1" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
["10.1"]
==============================================================
Converted from testFilterDoubleDimension()
=== case
Filter double dimension
=== SQL
SELECT dim1 FROM numfoo WHERE d1 = 1.7 LIMIT 1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
=== plan
LogicalSort(fetch=[1])
  LogicalProject(dim1=[$4])
    LogicalFilter(condition=[=($2, 1.7)])
      LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "resultFormat" : "compactedList",
  "limit" : 1,
  "filter" : {
    "type" : "selector",
    "dimension" : "d1",
    "value" : "1.7"
  },
  "columns" : [ "dim1" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
["10.1"]
==============================================================
Converted from testFilterLongDimension()
=== case
Filter long dimension
=== SQL
SELECT dim1 FROM numfoo WHERE l1 = 7 LIMIT 1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
=== plan
LogicalSort(fetch=[1])
  LogicalProject(dim1=[$4])
    LogicalFilter(condition=[=($12, 7)])
      LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "resultFormat" : "compactedList",
  "limit" : 1,
  "filter" : {
    "type" : "selector",
    "dimension" : "l1",
    "value" : "7"
  },
  "columns" : [ "dim1" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
[""]
==============================================================
Converted from testTrigonometricFunction()
=== case
Trigonometric function
=== SQL
SELECT
  exp(count(*)) + 10,
  sin(pi / 6), cos(pi / 6),
  tan(pi / 6), cot(pi / 6),
  asin(exp(count(*)) / 2),
  acos(exp(count(*)) / 2),
  atan(exp(count(*)) / 2),
  atan2(exp(count(*)), 1)
FROM druid.foo
WHERE dim2 = 0
=== options
sqlCompatibleNulls=both
typedCompare=true
vectorize=true
=== plan
LogicalProject(EXPR$0=[+(EXP($0), 10)], EXPR$1=[SIN(/(PI, 6))], EXPR$2=[COS(/(PI, 6))], EXPR$3=[TAN(/(PI, 6))], EXPR$4=[COT(/(PI, 6))], EXPR$5=[ASIN(/(EXP($0), 2))], EXPR$6=[ACOS(/(EXP($0), 2))], EXPR$7=[ATAN(/(EXP($0), 2))], EXPR$8=[ATAN2(EXP($0), 1)])
  LogicalAggregate(group=[{}], agg#0=[COUNT()])
    LogicalProject($f0=[0])
      LogicalFilter(condition=[=(CAST($3):INTEGER, 0)])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "bound",
    "dimension" : "dim2",
    "lower" : "0",
    "upper" : "0",
    "ordering" : {
      "type" : "numeric"
    }
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "(exp(\"a0\") + 10)"
  }, {
    "type" : "expression",
    "name" : "p1",
    "expression" : "0.49999999999999994"
  }, {
    "type" : "expression",
    "name" : "p2",
    "expression" : "0.8660254037844387"
  }, {
    "type" : "expression",
    "name" : "p3",
    "expression" : "0.5773502691896257"
  }, {
    "type" : "expression",
    "name" : "p4",
    "expression" : "1.7320508075688776"
  }, {
    "type" : "expression",
    "name" : "p5",
    "expression" : "asin((exp(\"a0\") / 2))"
  }, {
    "type" : "expression",
    "name" : "p6",
    "expression" : "acos((exp(\"a0\") / 2))"
  }, {
    "type" : "expression",
    "name" : "p7",
    "expression" : "atan((exp(\"a0\") / 2))"
  }, {
    "type" : "expression",
    "name" : "p8",
    "expression" : "atan2(exp(\"a0\"),1)"
  } ]
}
=== results
[11.0,0.5,0.866,0.57735,1.732050,0.523599,1.0472,0.4636,0.7854]
==============================================================
Converted from testRadiansAndDegrees()
=== case
Radians and degrees
=== SQL
SELECT RADIANS(m1 * 15)/DEGREES(m2)
FROM numfoo
WHERE dim1 = '1'
=== options
sqlCompatibleNulls=both
typedCompare=true
vectorize=true
=== schema
EXPR$0 DOUBLE
=== plan
LogicalProject(EXPR$0=[/(RADIANS(*($14, 15)), DEGREES($15))])
  LogicalFilter(condition=[=($4, '1')])
    LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "(toRadians((\"m1\" * 15)) / toDegrees(\"m2\"))",
    "outputType" : "DOUBLE"
  } ],
  "resultFormat" : "compactedList",
  "filter" : {
    "type" : "selector",
    "dimension" : "dim1",
    "value" : "1"
  },
  "columns" : [ "v0" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
[0.004569]
==============================================================
Converted from testTimestampDiff()
=== case
Timestamp diff
=== SQL
SELECT
  TIMESTAMPDIFF(DAY, TIMESTAMP '1999-01-01 00:00:00', __time),
  TIMESTAMPDIFF(DAY, __time, DATE '2001-01-01'),
  TIMESTAMPDIFF(HOUR, TIMESTAMP '1999-12-31 01:00:00', __time),
  TIMESTAMPDIFF(MINUTE, TIMESTAMP '1999-12-31 23:58:03', __time),
  TIMESTAMPDIFF(SECOND, TIMESTAMP '1999-12-31 23:59:03', __time),
  TIMESTAMPDIFF(MONTH, TIMESTAMP '1999-11-01 00:00:00', __time),
  TIMESTAMPDIFF(YEAR, TIMESTAMP '1996-11-01 00:00:00', __time),
  TIMESTAMPDIFF(QUARTER, TIMESTAMP '1996-10-01 00:00:00', __time),
  TIMESTAMPDIFF(WEEK, TIMESTAMP '1998-10-01 00:00:00', __time)
FROM druid.foo
LIMIT 2
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 INTEGER
EXPR$1 INTEGER
EXPR$2 INTEGER
EXPR$3 INTEGER
EXPR$4 INTEGER
EXPR$5 INTEGER
EXPR$6 INTEGER
EXPR$7 INTEGER
EXPR$8 INTEGER
=== plan
LogicalSort(fetch=[2])
  LogicalProject(EXPR$0=[CAST(/INT(Reinterpret(-($0, 1999-01-01 00:00:00)), 86400000)):INTEGER NOT NULL], EXPR$1=[CAST(/INT(Reinterpret(-(2001-01-01, $0)), 86400000)):INTEGER NOT NULL], EXPR$2=[CAST(/INT(Reinterpret(-($0, 1999-12-31 01:00:00)), 3600000)):INTEGER NOT NULL], EXPR$3=[CAST(/INT(Reinterpret(-($0, 1999-12-31 23:58:03)), 60000)):INTEGER NOT NULL], EXPR$4=[CAST(/INT(Reinterpret(-($0, 1999-12-31 23:59:03)), 1000)):INTEGER NOT NULL], EXPR$5=[CAST(Reinterpret(-($0, 1999-11-01 00:00:00))):INTEGER NOT NULL], EXPR$6=[CAST(/INT(Reinterpret(-($0, 1996-11-01 00:00:00)), 12)):INTEGER NOT NULL], EXPR$7=[/INT(CAST(Reinterpret(-($0, 1996-10-01 00:00:00))):INTEGER NOT NULL, 3)], EXPR$8=[/INT(CAST(/INT(Reinterpret(-($0, 1998-10-01 00:00:00)), 1000)):INTEGER NOT NULL, 604800)])
    LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "div((\"__time\" - 915148800000),86400000)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v1",
    "expression" : "div((978307200000 - \"__time\"),86400000)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v2",
    "expression" : "div((\"__time\" - 946602000000),3600000)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v3",
    "expression" : "div((\"__time\" - 946684683000),60000)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v4",
    "expression" : "div((\"__time\" - 946684743000),1000)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v5",
    "expression" : "subtract_months(\"__time\",941414400000,'UTC')",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v6",
    "expression" : "div(subtract_months(\"__time\",846806400000,'UTC'),12)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v7",
    "expression" : "div(subtract_months(\"__time\",844128000000,'UTC'),3)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v8",
    "expression" : "div(div((\"__time\" - 907200000000),1000),604800)",
    "outputType" : "LONG"
  } ],
  "resultFormat" : "compactedList",
  "limit" : 2,
  "columns" : [ "v0", "v1", "v2", "v3", "v4", "v5", "v6", "v7", "v8" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
[365,366,23,1,57,2,3,13,65]
[366,365,47,1441,86457,2,3,13,65]
==============================================================
Converted from testTimestampCeil()
=== case
Timestamp ceil
=== SQL
SELECT CEIL(TIMESTAMP '2000-01-01 00:00:00' TO DAY),
CEIL(TIMESTAMP '2000-01-01 01:00:00' TO DAY)
FROM druid.foo
LIMIT 1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 TIMESTAMP(0)
EXPR$1 TIMESTAMP(0)
=== plan
LogicalSort(fetch=[1])
  LogicalProject(EXPR$0=[CEIL(2000-01-01 00:00:00, FLAG(DAY))], EXPR$1=[CEIL(2000-01-01 01:00:00, FLAG(DAY))])
    LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "946684800000",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v1",
    "expression" : "946771200000",
    "outputType" : "LONG"
  } ],
  "resultFormat" : "compactedList",
  "limit" : 1,
  "columns" : [ "v0", "v1" ],
  "legacy" : false,
  "granularity" : {
    "type" : "all"
  }
}
=== results
[946684800000,946771200000]
==============================================================
Converted from testNvlColumns()
Cannot vectorize due to usage of expressions.
=== case
Nvl columns
=== SQL
SELECT NVL(dim2, dim1), COUNT(*) FROM druid.foo GROUP BY NVL(dim2, dim1)
=== options
vectorize=false
=== schema
EXPR$0 VARCHAR
EXPR$1 BIGINT
=== plan
LogicalAggregate(group=[{0}], EXPR$1=[COUNT()])
  LogicalProject(EXPR$0=[CASE(IS NOT NULL($3), $3, $2)])
    LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "case_searched(notnull(\"dim2\"),\"dim2\",\"dim1\")",
    "outputType" : "STRING"
  } ],
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== run
=== options
sqlCompatibleNulls=false
=== results
["10.1",1]
["2",1]
["a",2]
["abc",2]
=== run
=== options
sqlCompatibleNulls=true
=== results
["",1]
["10.1",1]
["a",2]
["abc",2]
==============================================================
Converted from testGroupByWithLiteralInSubqueryGrouping()
=== case
Group by with literal in subquery grouping
=== SQL
SELECT
   t1, t2
  FROM
   ( SELECT
     'dummy' as t1,
     CASE
       WHEN
         dim4 = 'b'
       THEN dim4
       ELSE NULL
     END AS t2
     FROM
       numfoo
     GROUP BY
       dim4
   )
 GROUP BY
   t1,t2
=== options
vectorize=true
=== schema
t1 CHAR(5)
t2 VARCHAR
=== plan
LogicalAggregate(group=[{0, 1}])
  LogicalProject(t1=['dummy'], t2=[CASE(=($0, 'b'), $0, null:VARCHAR)])
    LogicalAggregate(group=[{0}])
      LogicalProject(dim4=[$7])
        LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "query",
    "query" : {
      "queryType" : "groupBy",
      "dataSource" : {
        "type" : "table",
        "name" : "numfoo"
      },
      "intervals" : {
        "type" : "intervals",
        "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
      },
      "granularity" : {
        "type" : "all"
      },
      "dimensions" : [ {
        "type" : "default",
        "dimension" : "dim4",
        "outputName" : "_d0",
        "outputType" : "STRING"
      } ],
      "limitSpec" : {
        "type" : "NoopLimitSpec"
      }
    }
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "'dummy'",
    "outputType" : "STRING"
  }, {
    "type" : "expression",
    "name" : "v1",
    "expression" : "case_searched((\"_d0\" == 'b'),\"_d0\",null)",
    "outputType" : "STRING"
  } ],
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "STRING"
  }, {
    "type" : "default",
    "dimension" : "v1",
    "outputName" : "d1",
    "outputType" : "STRING"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== run
=== options
sqlCompatibleNulls=false
=== results
["dummy",""]
["dummy","b"]
=== run
=== options
sqlCompatibleNulls=true
=== results
["dummy",null]
["dummy","b"]
==============================================================
Converted from testLeftRightStringOperators()
=== case
Left right string operators
=== SQL
SELECT
  dim1,  LEFT(dim1, 2),
  RIGHT(dim1, 2)
FROM druid.foo
GROUP BY dim1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
EXPR$1 VARCHAR
EXPR$2 VARCHAR
=== plan
LogicalProject(dim1=[$0], EXPR$1=[LEFT($0, 2)], EXPR$2=[RIGHT($0, 2)])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "left(\"d0\",2)"
  }, {
    "type" : "expression",
    "name" : "p1",
    "expression" : "right(\"d0\",2)"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== results
["","",""]
["1","1","1"]
["10.1","10",".1"]
["2","2","2"]
["abc","ab","bc"]
["def","de","ef"]
==============================================================
Converted from testQueryContextOuterLimit()
No existing limit
=== case
Query context outer limit (1)
=== SQL
SELECT dim1
FROM druid.foo
GROUP BY dim1
ORDER BY dim1 DESC
=== context
sqlOuterLimit=4
=== options
vectorize=true
=== plan
LogicalSort(sort0=[$0], dir0=[DESC], fetch=[4:BIGINT])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "topN",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "dimension" : {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  },
  "metric" : {
    "type" : "inverted",
    "metric" : {
      "type" : "dimension",
      "ordering" : {
        "type" : "lexicographic"
      }
    }
  },
  "threshold" : 4,
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ ],
  "context" : {
    "sqlOuterLimit" : 4
  }
}
=== run
=== options
sqlCompatibleNulls=false
=== results
[""]
["def"]
["abc"]
["2"]
=== run
=== options
sqlCompatibleNulls=true
=== results
["def"]
["abc"]
["2"]
["10.1"]
==============================================================
Converted from testQueryContextOuterLimit()
Existing limit greater than context limit, override existing limit
=== case
Query context outer limit (2)
=== SQL
SELECT dim1
FROM druid.foo
GROUP BY dim1
ORDER BY dim1 DESC
LIMIT 9
=== context
sqlOuterLimit=4
=== plan
LogicalSort(sort0=[$0], dir0=[DESC], fetch=[4:BIGINT])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "topN",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "dimension" : {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  },
  "metric" : {
    "type" : "inverted",
    "metric" : {
      "type" : "dimension",
      "ordering" : {
        "type" : "lexicographic"
      }
    }
  },
  "threshold" : 4,
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ ],
  "context" : {
    "sqlOuterLimit" : 4
  }
}
==============================================================
Converted from testQueryContextOuterLimit()
Existing limit less than context limit, keep existing limit
=== case
Query context outer limit (3)
=== SQL
SELECT dim1
FROM druid.foo
GROUP BY dim1
ORDER BY dim1 DESC
LIMIT 2
=== context
sqlOuterLimit=4
=== plan
LogicalSort(sort0=[$0], dir0=[DESC], fetch=[2])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "topN",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "dimension" : {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  },
  "metric" : {
    "type" : "inverted",
    "metric" : {
      "type" : "dimension",
      "ordering" : {
        "type" : "lexicographic"
      }
    }
  },
  "threshold" : 2,
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ ],
  "context" : {
    "sqlOuterLimit" : 4
  }
}
==============================================================
Converted from testRepeatedIdenticalVirtualExpressionGrouping()
=== case
Repeated identical virtual expression grouping
=== SQL
SELECT
	CASE dim1 WHEN NULL THEN FALSE ELSE TRUE END AS col_a,
	CASE dim2 WHEN NULL THEN FALSE ELSE TRUE END AS col_b
FROM foo
GROUP BY 1, 2
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
col_a BOOLEAN
col_b BOOLEAN
=== plan
LogicalAggregate(group=[{0, 1}])
  LogicalProject(col_a=[true], col_b=[true])
    LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "1",
    "outputType" : "LONG"
  } ],
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "LONG"
  }, {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d1",
    "outputType" : "LONG"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== results
[true,true]
==============================================================
Converted from testValidationErrorNullLiteralIllegal()
=== case
Validation error null literal illegal
=== SQL
SELECT REGEXP_LIKE('x', NULL)
=== error
!.*Illegal use of 'NULL'
==============================================================
Converted from testValidationErrorNonLiteralIllegal()
=== case
Validation error non literal illegal
=== SQL
SELECT REGEXP_LIKE('x', dim1) FROM foo
=== error
!.*Argument to function 'REGEXP_LIKE' must be a literal
==============================================================
Converted from testValidationErrorWrongTypeLiteral()
=== case
Validation error wrong type literal
=== SQL
SELECT REGEXP_LIKE('x', 1) FROM foo
=== error
!.*Cannot apply 'REGEXP_LIKE' to arguments of type 'REGEXP_LIKE\(<CHAR\(1\)>, <INTEGER>\)'. Supported form\(s\): 'REGEXP_LIKE\(<CHARACTER>, <CHARACTER>\)'
