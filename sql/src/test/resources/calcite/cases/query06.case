Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
==============================================================
Converted from testCountStarWithLongColumnFilters()
=== case
Count star with long column filters
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE cnt >= 3 OR cnt = 1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[OR(>=($1, 3), =($1, 1))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "or",
    "fields" : [ {
      "type" : "bound",
      "dimension" : "cnt",
      "lower" : "3",
      "ordering" : {
        "type" : "numeric"
      }
    }, {
      "type" : "selector",
      "dimension" : "cnt",
      "value" : "1"
    } ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
=== results
[6]
==============================================================
Converted from testCountStarWithLongColumnFiltersOnFloatLiterals()
=== case
Count star with long column filters on float literals (1)
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE cnt > 1.1
  and cnt < 100000001.0
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[AND(>($1, 1.1:DECIMAL(2, 1)), <($1, 100000001.0:DECIMAL(10, 1)))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "bound",
    "dimension" : "cnt",
    "lower" : "1.1",
    "upper" : "100000001.0",
    "lowerStrict" : true,
    "upperStrict" : true,
    "ordering" : {
      "type" : "numeric"
    }
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
=== results
[0]
==============================================================
Converted from testCountStarWithLongColumnFiltersOnFloatLiterals()
=== case
Count star with long column filters on float literals (2)
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE cnt = 1.0
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[=(CAST($1):DECIMAL(19, 0) NOT NULL, 1.0)])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "selector",
    "dimension" : "cnt",
    "value" : "1.0"
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
==============================================================
Converted from testCountStarWithLongColumnFiltersOnFloatLiterals()
=== case
Count star with long column filters on float literals (3)
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE cnt = 100000001.0
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[=(CAST($1):DECIMAL(19, 0) NOT NULL, 100000001.0)])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "selector",
    "dimension" : "cnt",
    "value" : "100000001.0"
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
==============================================================
Converted from testCountStarWithLongColumnFiltersOnFloatLiterals()
=== case
Count star with long column filters on float literals (4)
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE cnt = 1.0
   or cnt = 100000001.0
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[OR(=(CAST($1):DECIMAL(19, 0) NOT NULL, 1.0), =(CAST($1):DECIMAL(19, 0) NOT NULL, 100000001.0))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "in",
    "dimension" : "cnt",
    "values" : [ "1.0", "100000001.0" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
==============================================================
Converted from testCountStarWithLongColumnFiltersOnTwoPoints()
=== case
Count star with long column filters on two points
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE cnt = 1
   OR cnt = 2
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[OR(=($1, 1), =($1, 2))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "in",
    "dimension" : "cnt",
    "values" : [ "1", "2" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
=== results
[6]
==============================================================
Converted from testFilterOnStringAsNumber()
=== case
Filter on string as number
=== SQL
SELECT distinct dim1
FROM druid.foo
WHERE dim1 = 10
   OR (floor(CAST(dim1 AS float)) = 10.00 and
       CAST(dim1 AS float) > 9 and
       CAST(dim1 AS float) <= 10.5)
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
=== plan
LogicalAggregate(group=[{0}])
  LogicalProject(dim1=[$2])
    LogicalFilter(condition=[OR(=(CAST($2):INTEGER, 10), AND(=(CAST(FLOOR(CAST($2):FLOAT)):DOUBLE, 10.00), >(CAST($2):FLOAT, 9), <=(CAST($2):FLOAT, 10.5:DECIMAL(3, 1))))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "floor(CAST(\"dim1\", 'DOUBLE'))",
    "outputType" : "DOUBLE"
  } ],
  "filter" : {
    "type" : "or",
    "fields" : [ {
      "type" : "bound",
      "dimension" : "dim1",
      "lower" : "10",
      "upper" : "10",
      "ordering" : {
        "type" : "numeric"
      }
    }, {
      "type" : "and",
      "fields" : [ {
        "type" : "selector",
        "dimension" : "v0",
        "value" : "10.00"
      }, {
        "type" : "bound",
        "dimension" : "dim1",
        "lower" : "9",
        "upper" : "10.5",
        "lowerStrict" : true,
        "ordering" : {
          "type" : "numeric"
        }
      } ]
    } ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== results
["10.1"]
==============================================================
Converted from testSimpleLongAggregations()
=== case
Simple long aggregations
=== SQL
SELECT  MIN(l1), MIN(cnt), MAX(l1)
FROM druid.numfoo
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
EXPR$1 BIGINT
EXPR$2 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[MIN($0)], EXPR$1=[MIN($1)], EXPR$2=[MAX($0)])
  LogicalProject(l1=[$12], cnt=[$1])
    LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "longMin",
    "name" : "a0",
    "fieldName" : "l1"
  }, {
    "type" : "longMin",
    "name" : "a1",
    "fieldName" : "cnt"
  }, {
    "type" : "longMax",
    "name" : "a2",
    "fieldName" : "l1"
  } ]
}
=== results
[0,1,325323]
==============================================================
Converted from testSimpleDoubleAggregations()
=== case
Simple double aggregations
=== SQL
SELECT  MIN(d1), MAX(d1)
FROM druid.numfoo
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 DOUBLE
EXPR$1 DOUBLE
=== plan
LogicalAggregate(group=[{}], EXPR$0=[MIN($0)], EXPR$1=[MAX($0)])
  LogicalProject(d1=[$2])
    LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "doubleMin",
    "name" : "a0",
    "fieldName" : "d1"
  }, {
    "type" : "doubleMax",
    "name" : "a1",
    "fieldName" : "d1"
  } ]
}
=== results
[0.0,1.7]
==============================================================
Converted from testSimpleFloatAggregations()
=== case
Simple float aggregations
=== SQL
SELECT  MIN(m1), MAX(m1)
FROM druid.numfoo
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 FLOAT
EXPR$1 FLOAT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[MIN($0)], EXPR$1=[MAX($0)])
  LogicalProject(m1=[$14])
    LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "floatMin",
    "name" : "a0",
    "fieldName" : "m1"
  }, {
    "type" : "floatMax",
    "name" : "a1",
    "fieldName" : "m1"
  } ]
}
=== results
[1.0,6.0]
==============================================================
Converted from testSimpleAggregations()
=== case
Simple aggregations
=== SQL
SELECT
  COUNT(*),
  COUNT(cnt),
  COUNT(dim1),
  AVG(cnt),
  SUM(cnt),
  SUM(cnt) + MIN(cnt) + MAX(cnt),
  COUNT(dim2),
  COUNT(d1),
  AVG(d1)
FROM druid.numfoo
=== options
sqlCompatibleNulls=false
vectorize=true
=== schema
EXPR$0 BIGINT
EXPR$1 BIGINT
EXPR$2 BIGINT
EXPR$3 BIGINT
EXPR$4 BIGINT
EXPR$5 BIGINT
EXPR$6 BIGINT
EXPR$7 BIGINT
EXPR$8 DOUBLE
=== plan
LogicalProject(EXPR$0=[$0], EXPR$1=[$0], EXPR$2=[$1], EXPR$3=[$2], EXPR$4=[$3], EXPR$5=[+(+($3, $4), $5)], EXPR$6=[$6], EXPR$7=[$0], EXPR$8=[$7])
  LogicalAggregate(group=[{}], EXPR$0=[COUNT()], EXPR$2=[COUNT($1)], EXPR$3=[AVG($0)], EXPR$4=[SUM($0)], agg#4=[MIN($0)], agg#5=[MAX($0)], EXPR$6=[COUNT($2)], EXPR$8=[AVG($3)])
    LogicalProject(cnt=[$1], dim1=[$4], dim2=[$5], d1=[$2])
      LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a1"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : null
      }
    },
    "name" : "a1"
  }, {
    "type" : "longSum",
    "name" : "a2:sum",
    "fieldName" : "cnt"
  }, {
    "type" : "count",
    "name" : "a2:count"
  }, {
    "type" : "longSum",
    "name" : "a3",
    "fieldName" : "cnt"
  }, {
    "type" : "longMin",
    "name" : "a4",
    "fieldName" : "cnt"
  }, {
    "type" : "longMax",
    "name" : "a5",
    "fieldName" : "cnt"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a6"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim2",
        "value" : null
      }
    },
    "name" : "a6"
  }, {
    "type" : "doubleSum",
    "name" : "a7:sum",
    "fieldName" : "d1"
  }, {
    "type" : "count",
    "name" : "a7:count"
  } ],
  "postAggregations" : [ {
    "type" : "arithmetic",
    "name" : "a2",
    "fn" : "quotient",
    "fields" : [ {
      "type" : "fieldAccess",
      "fieldName" : "a2:sum"
    }, {
      "type" : "fieldAccess",
      "fieldName" : "a2:count"
    } ]
  }, {
    "type" : "arithmetic",
    "name" : "a7",
    "fn" : "quotient",
    "fields" : [ {
      "type" : "fieldAccess",
      "fieldName" : "a7:sum"
    }, {
      "type" : "fieldAccess",
      "fieldName" : "a7:count"
    } ]
  }, {
    "type" : "expression",
    "name" : "p0",
    "expression" : "((\"a3\" + \"a4\") + \"a5\")"
  } ]
}
=== results
[6,6,5,1,6,8,3,6,0.45]
==============================================================
Converted from testSimpleAggregations()
=== case
Simple aggregations
=== SQL copy
=== options
sqlCompatibleNulls=true
vectorize=true
=== schema copy
=== plan copy
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a1"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "cnt"
      }
    },
    "name" : "a1"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a2"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1"
      }
    },
    "name" : "a2"
  }, {
    "type" : "longSum",
    "name" : "a3:sum",
    "fieldName" : "cnt"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a3:count"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "cnt"
      }
    },
    "name" : "a3:count"
  }, {
    "type" : "longSum",
    "name" : "a4",
    "fieldName" : "cnt"
  }, {
    "type" : "longMin",
    "name" : "a5",
    "fieldName" : "cnt"
  }, {
    "type" : "longMax",
    "name" : "a6",
    "fieldName" : "cnt"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a7"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim2"
      }
    },
    "name" : "a7"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a8"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "d1"
      }
    },
    "name" : "a8"
  }, {
    "type" : "doubleSum",
    "name" : "a9:sum",
    "fieldName" : "d1"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a9:count"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "d1"
      }
    },
    "name" : "a9:count"
  } ],
  "postAggregations" : [ {
    "type" : "arithmetic",
    "name" : "a3",
    "fn" : "quotient",
    "fields" : [ {
      "type" : "fieldAccess",
      "fieldName" : "a3:sum"
    }, {
      "type" : "fieldAccess",
      "fieldName" : "a3:count"
    } ]
  }, {
    "type" : "arithmetic",
    "name" : "a9",
    "fn" : "quotient",
    "fields" : [ {
      "type" : "fieldAccess",
      "fieldName" : "a9:sum"
    }, {
      "type" : "fieldAccess",
      "fieldName" : "a9:count"
    } ]
  }, {
    "type" : "expression",
    "name" : "p0",
    "expression" : "((\"a4\" + \"a5\") + \"a6\")"
  } ],
  "context" : {
    "defaultTimeout" : 300000,
    "maxScatterGatherBytes" : 9223372036854775807,
    "sqlCurrentTimestamp" : "2000-01-01T00:00:00Z",
    "sqlQueryId" : "dummy"
  }
}
=== results
[6,6,6,1,6,8,4,3,0.9]
==============================================================
Converted from testGroupByWithSortOnPostAggregationDefault()
By default this query uses topN.
=== case
Group by with sort on post aggregation default
=== SQL
SELECT dim1, MIN(m1) + MAX(m1) AS x
FROM druid.foo
GROUP BY dim1
ORDER BY x
LIMIT 3
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
x FLOAT
=== plan
LogicalSort(sort0=[$1], dir0=[ASC], fetch=[3])
  LogicalProject(dim1=[$0], x=[+($1, $2)])
    LogicalAggregate(group=[{0}], agg#0=[MIN($1)], agg#1=[MAX($1)])
      LogicalProject(dim1=[$2], m1=[$5])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "topN",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "dimension" : {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  },
  "metric" : {
    "type" : "inverted",
    "metric" : {
      "type" : "numeric",
      "metric" : "p0"
    }
  },
  "threshold" : 3,
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "floatMin",
    "name" : "a0",
    "fieldName" : "m1"
  }, {
    "type" : "floatMax",
    "name" : "a1",
    "fieldName" : "m1"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "(\"a0\" + \"a1\")"
  } ]
}
=== results
["",2.0]
["10.1",4.0]
["2",6.0]
==============================================================
Converted from testGroupByWithSortOnPostAggregationNoTopNConfig()
Use PlannerConfig to disable topN, so this query becomes a groupBy.
=== case
Group by with sort on post aggregation no top n config
=== SQL
SELECT dim1, MIN(m1) + MAX(m1) AS x FROM druid.foo GROUP BY dim1 ORDER BY x LIMIT 3
=== options
planner.maxTopNLimit=0
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
x FLOAT
=== plan
LogicalSort(sort0=[$1], dir0=[ASC], fetch=[3])
  LogicalProject(dim1=[$0], x=[+($1, $2)])
    LogicalAggregate(group=[{0}], agg#0=[MIN($1)], agg#1=[MAX($1)])
      LogicalProject(dim1=[$2], m1=[$5])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "aggregations" : [ {
    "type" : "floatMin",
    "name" : "a0",
    "fieldName" : "m1"
  }, {
    "type" : "floatMax",
    "name" : "a1",
    "fieldName" : "m1"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "(\"a0\" + \"a1\")"
  } ],
  "limitSpec" : {
    "type" : "default",
    "columns" : [ {
      "dimension" : "p0",
      "direction" : "ascending",
      "dimensionOrder" : {
        "type" : "numeric"
      }
    } ],
    "limit" : 3
  }
}
=== results
["",2.0]
["10.1",4.0]
["2",6.0]
==============================================================
Converted from testGroupByWithSortOnPostAggregationNoTopNContext()
=== case
Group by with sort on post aggregation no top n context
=== SQL
SELECT dim1, MIN(m1) + MAX(m1) AS x FROM druid.foo GROUP BY dim1 ORDER BY x LIMIT 3
=== context
useApproximateTopN=false
=== options
sqlCompatibleNulls=both
vectorize=true
=== plan
LogicalSort(sort0=[$1], dir0=[ASC], fetch=[3])
  LogicalProject(dim1=[$0], x=[+($1, $2)])
    LogicalAggregate(group=[{0}], agg#0=[MIN($1)], agg#1=[MAX($1)])
      LogicalProject(dim1=[$2], m1=[$5])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "aggregations" : [ {
    "type" : "floatMin",
    "name" : "a0",
    "fieldName" : "m1"
  }, {
    "type" : "floatMax",
    "name" : "a1",
    "fieldName" : "m1"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "(\"a0\" + \"a1\")"
  } ],
  "limitSpec" : {
    "type" : "default",
    "columns" : [ {
      "dimension" : "p0",
      "direction" : "ascending",
      "dimensionOrder" : {
        "type" : "numeric"
      }
    } ],
    "limit" : 3
  },
  "context" : {
    "useApproximateTopN" : false
  }
}
=== results
["",2.0]
["10.1",4.0]
["2",6.0]
==============================================================
Converted from testFilteredAggregations()
Use context to disable topN, so this query becomes a groupBy.
=== case
Filtered aggregations
=== SQL
SELECT
  SUM(case dim1 when 'abc' then cnt end),
  SUM(case dim1 when 'abc' then null else cnt end),
  SUM(case substring(dim1, 1, 1) when 'a' then cnt end),
  COUNT(dim2) filter(WHERE dim1 <> '1'),
  COUNT(CASE WHEN dim1 <> '1' THEN 'dummy' END),
  SUM(CASE WHEN dim1 <> '1' THEN 1 ELSE 0 END),
  SUM(cnt) filter(WHERE dim2 = 'a'),
  SUM(case when dim1 <> '1' then cnt end) filter(WHERE dim2 = 'a'),
  SUM(CASE WHEN dim1 <> '1' THEN cnt ELSE 0 END),
  MAX(CASE WHEN dim1 <> '1' THEN cnt END),
  COUNT(DISTINCT CASE WHEN dim1 <> '1' THEN m1 END),
  SUM(cnt) filter(WHERE dim2 = 'a' AND dim1 = 'b')
FROM druid.foo
=== options
vectorize=true
=== schema
EXPR$0 BIGINT
EXPR$1 BIGINT
EXPR$2 BIGINT
EXPR$3 BIGINT
EXPR$4 BIGINT
EXPR$5 BIGINT
EXPR$6 BIGINT
EXPR$7 BIGINT
EXPR$8 BIGINT
EXPR$9 BIGINT
EXPR$10 BIGINT
EXPR$11 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[SUM($0)], EXPR$1=[SUM($1)], EXPR$2=[SUM($2)], EXPR$3=[COUNT($3) FILTER $4], EXPR$4=[COUNT($5)], EXPR$5=[SUM($6)], EXPR$6=[SUM($7) FILTER $8], EXPR$7=[SUM($9) FILTER $8], EXPR$8=[SUM($10)], EXPR$9=[MAX($9)], EXPR$10=[COUNT(DISTINCT $11)], EXPR$11=[SUM($7) FILTER $12])
  LogicalProject($f0=[CASE(=($2, 'abc'), $1, null:BIGINT)], $f1=[CASE(=($2, 'abc'), null:BIGINT, $1)], $f2=[CASE(=(SUBSTRING($2, 1, 1), 'a'), $1, null:BIGINT)], dim2=[$3], $f4=[IS TRUE(<>($2, '1'))], $f5=[CASE(<>($2, '1'), 'dummy', null:CHAR(5))], $f6=[CASE(<>($2, '1'), 1, 0)], cnt=[$1], $f8=[IS TRUE(=($3, 'a'))], $f9=[CASE(<>($2, '1'), $1, null:BIGINT)], $f10=[CASE(<>($2, '1'), $1, 0:BIGINT)], $f11=[CASE(<>($2, '1'), $5, null:FLOAT)], $f12=[IS TRUE(AND(=($3, 'a'), =($2, 'b')))])
    LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a0",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "selector",
      "dimension" : "dim1",
      "value" : "abc"
    },
    "name" : "a0"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a1",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "abc"
      }
    },
    "name" : "a1"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a2",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "selector",
      "dimension" : "dim1",
      "value" : "a",
      "extractionFn" : {
        "type" : "substring",
        "index" : 0,
        "length" : 1
      }
    },
    "name" : "a2"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a3"
    },
    "filter" : {
      "type" : "and",
      "fields" : [ {
        "type" : "not",
        "field" : {
          "type" : "selector",
          "dimension" : "dim2",
          "value" : null
        }
      }, {
        "type" : "not",
        "field" : {
          "type" : "selector",
          "dimension" : "dim1",
          "value" : "1"
        }
      } ]
    },
    "name" : "a3"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a4"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a4"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a5"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a5"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a6",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "selector",
      "dimension" : "dim2",
      "value" : "a"
    },
    "name" : "a6"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a7",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "and",
      "fields" : [ {
        "type" : "selector",
        "dimension" : "dim2",
        "value" : "a"
      }, {
        "type" : "not",
        "field" : {
          "type" : "selector",
          "dimension" : "dim1",
          "value" : "1"
        }
      } ]
    },
    "name" : "a7"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a8",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a8"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longMax",
      "name" : "a9",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a9"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "cardinality",
      "name" : "a10",
      "fields" : [ {
        "type" : "default",
        "dimension" : "m1",
        "outputName" : "m1",
        "outputType" : "FLOAT"
      } ],
      "byRow" : false,
      "round" : true
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a10"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "longSum",
      "name" : "a11",
      "fieldName" : "cnt"
    },
    "filter" : {
      "type" : "and",
      "fields" : [ {
        "type" : "selector",
        "dimension" : "dim2",
        "value" : "a"
      }, {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "b"
      } ]
    },
    "name" : "a11"
  } ]
}
=== run
=== options
sqlCompatibleNulls=false
=== results
[1,5,1,2,5,5,2,1,5,1,5,0]
=== run
=== options
sqlCompatibleNulls=true
=== results
[1,5,1,3,5,5,2,1,5,1,5,null]
==============================================================
Converted from testCaseFilteredAggregationWithGroupBy()
=== case
Case filtered aggregation with group by
=== SQL
SELECT
  cnt,
  SUM(CASE WHEN dim1 <> '1' THEN 1 ELSE 0 END) + SUM(cnt)
FROM druid.foo
GROUP BY cnt
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
cnt BIGINT
EXPR$1 BIGINT
=== plan
LogicalProject(cnt=[$0], EXPR$1=[+($1, $2)])
  LogicalAggregate(group=[{0}], agg#0=[SUM($1)], agg#1=[SUM($0)])
    LogicalProject(cnt=[$1], $f1=[CASE(<>($2, '1'), 1, 0)])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "cnt",
    "outputName" : "d0",
    "outputType" : "LONG"
  } ],
  "aggregations" : [ {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a0"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a0"
  }, {
    "type" : "longSum",
    "name" : "a1",
    "fieldName" : "cnt"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "(\"a0\" + \"a1\")"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== results
[1,11]
==============================================================
Converted from testFilteredAggregationWithNotIn()
=== case
Filtered aggregation with not in
=== SQL
SELECT
  COUNT(*) filter(WHERE dim1 NOT IN ('1')),
  COUNT(dim2) filter(WHERE dim1 NOT IN ('1'))
FROM druid.foo
=== options
vectorize=true
=== schema
EXPR$0 BIGINT
EXPR$1 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT() FILTER $0], EXPR$1=[COUNT($1) FILTER $0])
  LogicalProject($f0=[IS TRUE(<>($2, '1'))], dim2=[$3])
    LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a0"
    },
    "filter" : {
      "type" : "not",
      "field" : {
        "type" : "selector",
        "dimension" : "dim1",
        "value" : "1"
      }
    },
    "name" : "a0"
  }, {
    "type" : "filtered",
    "aggregator" : {
      "type" : "count",
      "name" : "a1"
    },
    "filter" : {
      "type" : "and",
      "fields" : [ {
        "type" : "not",
        "field" : {
          "type" : "selector",
          "dimension" : "dim2",
          "value" : null
        }
      }, {
        "type" : "not",
        "field" : {
          "type" : "selector",
          "dimension" : "dim1",
          "value" : "1"
        }
      } ]
    },
    "name" : "a1"
  } ]
}
=== run
=== options
sqlCompatibleNulls=false
=== results
[5,2]
=== run
=== options
sqlCompatibleNulls=true
=== results
[5,3]
==============================================================
Converted from testExpressionAggregations()
Cannot vectorize due to expressions.
=== case
Expression aggregations
=== SQL
SELECT
  SUM(cnt * 3),
  LN(SUM(cnt) + SUM(m1)),
  MOD(SUM(cnt), 4),
  SUM(CHARACTER_LENGTH(CAST(cnt * 10 AS VARCHAR))),
  MAX(CHARACTER_LENGTH(dim2) + LN(m1)),
  MIN(CHARACTER_LENGTH(dim2) + LN(m1))
FROM druid.foo
=== options
vectorize=false
=== schema
EXPR$0 BIGINT
EXPR$1 DOUBLE
EXPR$2 INTEGER
EXPR$3 BIGINT
EXPR$4 DOUBLE
EXPR$5 DOUBLE
=== plan
LogicalProject(EXPR$0=[$0], EXPR$1=[LN(+($1, $2))], EXPR$2=[MOD($1, 4)], EXPR$3=[$3], EXPR$4=[$4], EXPR$5=[$5])
  LogicalAggregate(group=[{}], EXPR$0=[SUM($0)], agg#1=[SUM($1)], agg#2=[SUM($2)], EXPR$3=[SUM($3)], EXPR$4=[MAX($4)], EXPR$5=[MIN($4)])
    LogicalProject($f0=[*($1, 3)], cnt=[$1], m1=[$5], $f3=[CHAR_LENGTH(CAST(*($1, 10)):VARCHAR NOT NULL)], $f4=[+(CHAR_LENGTH($3), LN($5))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "(\"cnt\" * 3)",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v1",
    "expression" : "strlen(CAST((\"cnt\" * 10), 'STRING'))",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v2",
    "expression" : "(strlen(\"dim2\") + log(\"m1\"))",
    "outputType" : "DOUBLE"
  } ],
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "longSum",
    "name" : "a0",
    "fieldName" : "v0"
  }, {
    "type" : "longSum",
    "name" : "a1",
    "fieldName" : "cnt"
  }, {
    "type" : "doubleSum",
    "name" : "a2",
    "fieldName" : "m1"
  }, {
    "type" : "longSum",
    "name" : "a3",
    "fieldName" : "v1"
  }, {
    "type" : "doubleMax",
    "name" : "a4",
    "fieldName" : "v2"
  }, {
    "type" : "doubleMin",
    "name" : "a5",
    "fieldName" : "v2"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "log((\"a1\" + \"a2\"))"
  }, {
    "type" : "expression",
    "name" : "p1",
    "expression" : "(\"a1\" % 4)"
  } ]
}
=== run
=== options
sqlCompatibleNulls=false
=== results
[18,3.295836866004329,2,12,4.6094379124341005,0.6931471805599453]
=== run
=== options
sqlCompatibleNulls=true
=== results
[18,3.295836866004329,2,12,4.6094379124341005,1.0]
==============================================================
Converted from testExpressionFilteringAndGrouping()
=== case
Expression filtering and grouping
=== SQL
SELECT
  FLOOR(m1 / 2) * 2,
  COUNT(*)
FROM druid.foo
WHERE FLOOR(m1 / 2) * 2 > -1
GROUP BY FLOOR(m1 / 2) * 2
ORDER BY 1 DESC
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 FLOAT
EXPR$1 BIGINT
=== plan
LogicalSort(sort0=[$0], dir0=[DESC])
  LogicalAggregate(group=[{0}], EXPR$1=[COUNT()])
    LogicalProject(EXPR$0=[*(FLOOR(/($5, 2)), 2)])
      LogicalFilter(condition=[>(*(FLOOR(/($5, 2)), 2), -1)])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "(floor((\"m1\" / 2)) * 2)",
    "outputType" : "FLOAT"
  } ],
  "filter" : {
    "type" : "bound",
    "dimension" : "v0",
    "lower" : "-1",
    "lowerStrict" : true,
    "ordering" : {
      "type" : "numeric"
    }
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "FLOAT"
  } ],
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "limitSpec" : {
    "type" : "default",
    "columns" : [ {
      "dimension" : "d0",
      "direction" : "descending",
      "dimensionOrder" : {
        "type" : "numeric"
      }
    } ]
  }
}
=== results
[6.0,1]
[4.0,2]
[2.0,2]
[0.0,1]
==============================================================
Converted from testExpressionFilteringAndGroupingUsingCastToLong()
=== case
Expression filtering and grouping using cast to long
=== SQL
SELECT
  CAST(m1 AS BIGINT) / 2 * 2,
  COUNT(*)
FROM druid.foo
WHERE CAST(m1 AS BIGINT) / 2 * 2 > -1
GROUP BY CAST(m1 AS BIGINT) / 2 * 2
ORDER BY 1 DESC
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
EXPR$1 BIGINT
=== plan
LogicalSort(sort0=[$0], dir0=[DESC])
  LogicalAggregate(group=[{0}], EXPR$1=[COUNT()])
    LogicalProject(EXPR$0=[*(/(CAST($5):BIGINT NOT NULL, 2), 2)])
      LogicalFilter(condition=[>(*(/(CAST($5):BIGINT NOT NULL, 2), 2), -1)])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "((CAST(\"m1\", 'LONG') / 2) * 2)",
    "outputType" : "LONG"
  } ],
  "filter" : {
    "type" : "bound",
    "dimension" : "v0",
    "lower" : "-1",
    "lowerStrict" : true,
    "ordering" : {
      "type" : "numeric"
    }
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "LONG"
  } ],
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "limitSpec" : {
    "type" : "default",
    "columns" : [ {
      "dimension" : "d0",
      "direction" : "descending",
      "dimensionOrder" : {
        "type" : "numeric"
      }
    } ]
  }
}
=== results
[6,1]
[4,2]
[2,2]
[0,1]
==============================================================
Converted from testExpressionFilteringAndGroupingOnStringCastToNumber()
=== case
Expression filtering and grouping on string cast to number
=== SQL
SELECT
  FLOOR(CAST(dim1 AS FLOAT) / 2) * 2,
  COUNT(*)
FROM druid.foo
WHERE FLOOR(CAST(dim1 AS FLOAT) / 2) * 2 > -1
GROUP BY FLOOR(CAST(dim1 AS FLOAT) / 2) * 2
ORDER BY 1 DESC
=== options
vectorize=true
=== schema
EXPR$0 FLOAT
EXPR$1 BIGINT
=== plan
LogicalSort(sort0=[$0], dir0=[DESC])
  LogicalAggregate(group=[{0}], EXPR$1=[COUNT()])
    LogicalProject(EXPR$0=[*(FLOOR(/(CAST($2):FLOAT, 2)), 2)])
      LogicalFilter(condition=[>(*(FLOOR(/(CAST($2):FLOAT, 2)), 2), -1)])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "(floor((CAST(\"dim1\", 'DOUBLE') / 2)) * 2)",
    "outputType" : "FLOAT"
  } ],
  "filter" : {
    "type" : "bound",
    "dimension" : "v0",
    "lower" : "-1",
    "lowerStrict" : true,
    "ordering" : {
      "type" : "numeric"
    }
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "FLOAT"
  } ],
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "limitSpec" : {
    "type" : "default",
    "columns" : [ {
      "dimension" : "d0",
      "direction" : "descending",
      "dimensionOrder" : {
        "type" : "numeric"
      }
    } ]
  }
}
=== run
=== options
sqlCompatibleNulls=false
=== results
[10.0,1]
[2.0,1]
[0.0,4]
=== run
=== options
sqlCompatibleNulls=true
=== results
[10.0,1]
[2.0,1]
[0.0,1]
==============================================================
Converted from testInFilter()
=== case
In filter
=== SQL
SELECT dim1, COUNT(*)
FROM druid.foo
WHERE dim1 IN ('abc', 'def', 'ghi')
GROUP BY dim1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
EXPR$1 BIGINT
=== plan
LogicalAggregate(group=[{0}], EXPR$1=[COUNT()])
  LogicalProject(dim1=[$2])
    LogicalFilter(condition=[OR(=($2, 'abc'), =($2, 'def'), =($2, 'ghi'))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "in",
    "dimension" : "dim1",
    "values" : [ "abc", "def", "ghi" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== results
["abc",1]
["def",1]
==============================================================
Converted from testInFilterWith23Elements()
Regression test for https://github.com/apache/druid/issues/4203.
=== case
In filter with 23 elements
=== SQL
SELECT
  dim1,
  COUNT(*)
FROM druid.foo
WHERE dim1 IN ('abc','def','ghi','dummy0','dummy1','dummy2','dummy3','dummy4',
               'dummy5','dummy6','dummy7','dummy8','dummy9','dummy10','dummy11',
               'dummy12','dummy13','dummy14','dummy15','dummy16','dummy17',
               'dummy18','dummy19')
GROUP BY dim1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
EXPR$1 BIGINT
=== plan
LogicalAggregate(group=[{0}], EXPR$1=[COUNT()])
  LogicalProject(dim1=[$2])
    LogicalFilter(condition=[OR(=($2, 'abc'), =($2, 'def'), =($2, 'ghi'), =($2, 'dummy0'), =($2, 'dummy1'), =($2, 'dummy2'), =($2, 'dummy3'), =($2, 'dummy4'), =($2, 'dummy5'), =($2, 'dummy6'), =($2, 'dummy7'), =($2, 'dummy8'), =($2, 'dummy9'), =($2, 'dummy10'), =($2, 'dummy11'), =($2, 'dummy12'), =($2, 'dummy13'), =($2, 'dummy14'), =($2, 'dummy15'), =($2, 'dummy16'), =($2, 'dummy17'), =($2, 'dummy18'), =($2, 'dummy19'))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "in",
    "dimension" : "dim1",
    "values" : [ "abc", "def", "dummy0", "dummy1", "dummy10", "dummy11", "dummy12", "dummy13", "dummy14", "dummy15", "dummy16", "dummy17", "dummy18", "dummy19", "dummy2", "dummy3", "dummy4", "dummy5", "dummy6", "dummy7", "dummy8", "dummy9", "ghi" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
=== results
["abc",1]
["def",1]
==============================================================
Converted from testCountStarWithDegenerateFilter()
=== case
Count star with degenerate filter
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE dim2 = 'a'
  and (dim1 > 'a' OR dim1 < 'b')
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[AND(=($3, 'a'), OR(>($2, 'a'), <($2, 'b')))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "selector",
    "dimension" : "dim2",
    "value" : "a"
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
=== results
[2]
==============================================================
Converted from testCountStarWithNotOfDegenerateFilter()
HashJoinSegmentStorageAdapter is not vectorizable
=== case
Count star with not of degenerate filter
=== SQL
SELECT COUNT(*)
FROM druid.foo
WHERE dim2 = 'a'
  and not (dim1 > 'a' OR dim1 < 'b')
=== options
sqlCompatibleNulls=both
vectorize=false
=== schema
EXPR$0 BIGINT
=== plan
LogicalAggregate(group=[{}], EXPR$0=[COUNT()])
  LogicalProject($f0=[0])
    LogicalFilter(condition=[AND(=($3, 'a'), NOT(OR(>($2, 'a'), <($2, 'b'))))])
      LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "inline",
    "columnNames" : [ "dim1", "dim2" ],
    "columnTypes" : [ "STRING", "STRING" ],
    "rows" : [ ]
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "count",
    "name" : "a0"
  } ]
}
=== results
[0]
