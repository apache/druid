Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
==============================================================
Converted from testHumanReadableFormatFunctionExceptionWithWrongNumberType()
=== case
Human readable format function exception with wrong number type
=== SQL
SELECT HUMAN_READABLE_BINARY_BYTE_FORMAT('45678')
=== error
!.*\QCannot apply 'HUMAN_READABLE_BINARY_BYTE_FORMAT' to arguments of type 'HUMAN_READABLE_BINARY_BYTE_FORMAT(<CHAR(5)>)'\E.*
==============================================================
Converted from testHumanReadableFormatFunctionWithWrongPrecisionType()
=== case
Human readable format function with wrong precision type
=== SQL
SELECT HUMAN_READABLE_BINARY_BYTE_FORMAT(45678, '2')
=== error
!.*\QCannot apply 'HUMAN_READABLE_BINARY_BYTE_FORMAT' to arguments of type 'HUMAN_READABLE_BINARY_BYTE_FORMAT(<INTEGER>, <CHAR(1)>)'\E.*
==============================================================
Converted from testHumanReadableFormatFunctionWithInvalidNumberOfArguments()
Frankly speaking, the exception message thrown here is a little bit confusing
it says it's 'expecting 1 arguments' but actually
HUMAN_READABLE_BINARY_BYTE_FORMAT supports 1 or 2 arguments

The message is returned from
org.apache.calcite.sql.validate.SqlValidatorImpl#handleUnresolvedFunction,
and we can see from its implementation that it gets the min
number arguments to format the exception message.
=== case
Human readable format function with invalid number of arguments
=== SQL
SELECT HUMAN_READABLE_BINARY_BYTE_FORMAT(45678, 2, 1)
=== error
!.*Invalid number of arguments to function 'HUMAN_READABLE_BINARY_BYTE_FORMAT'. Was expecting 1 arguments
==============================================================
Converted from testCommonVirtualExpressionWithDifferentValueType()
=== case
Common virtual expression with different value type
=== SQL
select
  dim1,
  sum(cast(0 as bigint)) as s1,
  sum(cast(0 as double)) as s2
from druid.foo
where dim1 = 'none'
group by dim1
limit 1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
dim1 VARCHAR
s1 BIGINT
s2 DOUBLE
=== plan
LogicalSort(fetch=[1])
  LogicalAggregate(group=[{0}], s1=[SUM($1)], s2=[SUM($2)])
    LogicalProject(dim1=[$2], $f1=[0:BIGINT], $f2=[0:DOUBLE])
      LogicalFilter(condition=[=($2, 'none')])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "topN",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "virtualColumns" : [ {
    "type" : "expression",
    "name" : "v0",
    "expression" : "'none'",
    "outputType" : "STRING"
  }, {
    "type" : "expression",
    "name" : "v1",
    "expression" : "0",
    "outputType" : "LONG"
  }, {
    "type" : "expression",
    "name" : "v2",
    "expression" : "0",
    "outputType" : "DOUBLE"
  } ],
  "dimension" : {
    "type" : "default",
    "dimension" : "v0",
    "outputName" : "d0",
    "outputType" : "STRING"
  },
  "metric" : {
    "type" : "dimension",
    "ordering" : {
      "type" : "lexicographic"
    }
  },
  "threshold" : 1,
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "selector",
    "dimension" : "dim1",
    "value" : "none"
  },
  "granularity" : {
    "type" : "all"
  },
  "aggregations" : [ {
    "type" : "longSum",
    "name" : "a0",
    "fieldName" : "v1"
  }, {
    "type" : "doubleSum",
    "name" : "a1",
    "fieldName" : "v2"
  } ]
}
=== results
==============================================================
Converted from testReturnEmptyRowWhenGroupByIsConvertedToTimeseriesWithSingleConstantDimension()
When optimization in Grouping#applyProject is applied, and
it reduces a Group By query to a timeseries, we
want it to return empty bucket if no row matches

dim1 is not getting reduced to 'wat' in this case in Calcite
(ProjectMergeRule is not getting applied),
therefore the query is not optimized to a timeseries query
=== case
Return empty row when group by is converted to timeseries with single constant dimension
=== SQL
SELECT 'A' from foo WHERE m1 = 50 AND dim1 = 'wat' GROUP BY 'foobar'
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 CHAR(1)
=== plan
LogicalProject(EXPR$0=['A'])
  LogicalAggregate(group=[{0}])
    LogicalProject($f0=['foobar'])
      LogicalFilter(condition=[AND(=($5, 50), =($2, 'wat'))])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "and",
    "fields" : [ {
      "type" : "selector",
      "dimension" : "m1",
      "value" : "50"
    }, {
      "type" : "selector",
      "dimension" : "dim1",
      "value" : "wat"
    } ]
  },
  "granularity" : {
    "type" : "all"
  },
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "'A'"
  } ],
  "context" : {
    "skipEmptyBuckets" : true
  }
}
=== results
==============================================================
Converted from testReturnEmptyRowWhenGroupByIsConvertedToTimeseriesWithSingleConstantDimension()
=== case
Return empty row when group by is converted to timeseries with single constant dimension (1)
=== SQL
SELECT 'A' from foo WHERE dim1 = 'wat' GROUP BY dim1
=== schema
EXPR$0 CHAR(1)
=== plan
LogicalProject(EXPR$0=['A'])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalFilter(condition=[=($2, 'wat')])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "groupBy",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "selector",
    "dimension" : "dim1",
    "value" : "wat"
  },
  "granularity" : {
    "type" : "all"
  },
  "dimensions" : [ {
    "type" : "default",
    "dimension" : "dim1",
    "outputName" : "d0",
    "outputType" : "STRING"
  } ],
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "'A'"
  } ],
  "limitSpec" : {
    "type" : "NoopLimitSpec"
  }
}
==============================================================
Converted from testReturnEmptyRowWhenGroupByIsConvertedToTimeseriesWithMultipleConstantDimensions()
Sanity test, that even when dimensions are reduced, but should
produce a valid result (i.e. when filters are correct, then they should
=== case
Return empty row when group by is converted to timeseries with multiple constant dimensions (2)
=== SQL
SELECT 'A', dim1 from foo WHERE m1 = 50 AND dim1 = 'wat' GROUP BY dim1
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
EXPR$0 CHAR(1)
dim1 VARCHAR
=== plan
LogicalProject(EXPR$0=['A'], dim1=[$0])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalFilter(condition=[AND(=($5, 50), =($2, 'wat'))])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "and",
    "fields" : [ {
      "type" : "selector",
      "dimension" : "m1",
      "value" : "50"
    }, {
      "type" : "selector",
      "dimension" : "dim1",
      "value" : "wat"
    } ]
  },
  "granularity" : {
    "type" : "all"
  },
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "'A'"
  }, {
    "type" : "expression",
    "name" : "p1",
    "expression" : "'wat'"
  } ],
  "context" : {
    "skipEmptyBuckets" : true
  }
}
=== results
==============================================================
Converted from testReturnEmptyRowWhenGroupByIsConvertedToTimeseriesWithMultipleConstantDimensions()
=== case
Return empty row when group by is converted to timeseries with multiple constant dimensions (3)
=== SQL
SELECT 'A', dim1 from foo WHERE m1 = 2.0 AND dim1 = '10.1' GROUP BY dim1
=== schema
EXPR$0 CHAR(1)
dim1 VARCHAR
=== plan
LogicalProject(EXPR$0=['A'], dim1=[$0])
  LogicalAggregate(group=[{0}])
    LogicalProject(dim1=[$2])
      LogicalFilter(condition=[AND(=(CAST($5):DOUBLE NOT NULL, 2.0), =($2, '10.1'))])
        LogicalTableScan(table=[[druid, foo]])
=== native
{
  "queryType" : "timeseries",
  "dataSource" : {
    "type" : "table",
    "name" : "foo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "filter" : {
    "type" : "and",
    "fields" : [ {
      "type" : "selector",
      "dimension" : "m1",
      "value" : "2.0"
    }, {
      "type" : "selector",
      "dimension" : "dim1",
      "value" : "10.1"
    } ]
  },
  "granularity" : {
    "type" : "all"
  },
  "postAggregations" : [ {
    "type" : "expression",
    "name" : "p0",
    "expression" : "'A'"
  }, {
    "type" : "expression",
    "name" : "p1",
    "expression" : "'10.1'"
  } ],
  "context" : {
    "skipEmptyBuckets" : true
  }
}
==============================================================
Converted from testSurfaceErrorsWhenInsertingThroughIncorrectSelectStatment()
=== case
Surface errors when inserting through incorrect select statment
=== SQL
INSERT INTO druid.dst SELECT dim2, dim1, m1 FROM foo2 UNION SELECT dim1, dim2, m1 FROM foo PARTITIONED BY ALL TIME
=== exception
UnsupportedSQLQueryException
=== error
!.* Possible error: SQL requires 'UNION' but only 'UNION ALL' is supported.
==============================================================
Converted from testPlanWithInFilterLessThanInSubQueryThreshold()
=== case
Plan with in filter less than in sub query threshold
=== SQL
SELECT l1 FROM numfoo WHERE l1 IN (4842, 4844, 4845, 14905, 4853, 29064)
=== options
sqlCompatibleNulls=both
vectorize=true
=== schema
l1 BIGINT
=== plan
LogicalProject(l1=[$12])
  LogicalFilter(condition=[OR(=($12, 4842), =($12, 4844), =($12, 4845), =($12, 14905), =($12, 4853), =($12, 29064))])
    LogicalTableScan(table=[[druid, numfoo]])
=== native
{
  "queryType" : "scan",
  "dataSource" : {
    "type" : "table",
    "name" : "numfoo"
  },
  "intervals" : {
    "type" : "intervals",
    "intervals" : [ "-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z" ]
  },
  "resultFormat" : "compactedList",
  "filter" : {
    "type" : "in",
    "dimension" : "l1",
    "values" : [ "14905", "29064", "4842", "4844", "4845", "4853" ]
  },
  "columns" : [ "l1" ],
  "granularity" : {
    "type" : "all"
  }
}
=== results
