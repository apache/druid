# Live Log Streaming Diagnostics Guide

## ğŸ” Overview

This guide explains the comprehensive logging added to diagnose the live log streaming flow for Kubernetes tasks.

---

## ğŸ“Š Complete Log Flow

When a client requests live logs via `GET /druid/indexer/v1/task/{taskId}/log`, the request flows through these layers:

```
1. API Entry (Overlord HTTP)
   â†“
2. KubernetesTaskRunner.streamTaskLog()
   â†“
3. KubernetesWorkItem.streamTaskLogs()
   â†“
4. KubernetesPeonLifecycle.streamLogs()
   â†“
5. KubernetesPeonClient.getPeonLogWatcher()
   â†“
6. Kubernetes API (.watchLog())
```

Each layer now has detailed logging with unique markers.

---

## ğŸ·ï¸ Log Markers Reference

| Marker | Component | What It Logs |
|--------|-----------|--------------|
| `ğŸ“º [STREAM]` | KubernetesTaskRunner | API entry point, work item lookup |
| `ğŸ“º [WORKITEM]` | KubernetesWorkItem | Lifecycle delegation |
| `ğŸ“º [LIFECYCLE]` | KubernetesPeonLifecycle | State checks, stream creation |
| `ğŸ“º [K8S-CLIENT]` | KubernetesPeonClient | Kubernetes API calls |
| `ğŸ“Š [LIFECYCLE]` | KubernetesPeonLifecycle | State transitions |
| `âœ…` | All | Success messages |
| `âš ï¸` | All | Warnings (non-fatal issues) |
| `âŒ` | All | Errors |

---

## ğŸ¯ Successful Log Flow Example

**When everything works correctly:**

```
# 1. API Entry
ğŸ“º [STREAM] API request to stream logs for task [query-abc123] (offset=0)
ğŸ“º [STREAM] Found work item for task [query-abc123], delegating to streamTaskLogs()

# 2. Work Item Layer
ğŸ“º [WORKITEM] streamTaskLogs() called for task [query-abc123]
ğŸ“º [WORKITEM] Peon lifecycle exists for task [query-abc123], delegating to streamLogs()

# 3. Lifecycle Layer
ğŸ“º [LIFECYCLE] streamLogs() called for task [query-abc123]
ğŸ“º [LIFECYCLE] Current task state: RUNNING
ğŸ“º [LIFECYCLE] Task [query-abc123] is RUNNING, requesting LogWatch from Kubernetes client

# 4. K8s Client Layer
ğŸ“º [K8S-CLIENT] getPeonLogWatcher() called for task [query-abc123] (K8s job: query-abc123)
ğŸ“º [K8S-CLIENT] Namespace: default, Container: main
ğŸ“º [K8S-CLIENT] Calling Kubernetes API .watchLog() for job [query-abc123]
âœ… [K8S-CLIENT] Successfully created LogWatch for job [query-abc123]

# 5. Success Confirmation
âœ… [LIFECYCLE] Successfully obtained LogWatch for task [query-abc123], returning output stream
âœ… [WORKITEM] Peon lifecycle returned log stream for task [query-abc123]
âœ… [STREAM] Successfully obtained log stream for task [query-abc123]
```

**Result:** Client receives live streaming logs! âœ…

---

## âš ï¸ Failure Scenarios & Diagnostics

### Scenario 1: Task Not Found

**Logs:**
```
ğŸ“º [STREAM] API request to stream logs for task [query-unknown] (offset=0)
âš ï¸  [STREAM] No work item found for task [query-unknown] - task may not exist
```

**Cause:** Task ID is invalid or task hasn't been submitted to this runner.

**Fix:** Verify task ID is correct and task was submitted to this Overlord.

---

### Scenario 2: Task Not Started Yet

**Logs:**
```
ğŸ“º [STREAM] API request to stream logs for task [query-abc123] (offset=0)
ğŸ“º [STREAM] Found work item for task [query-abc123], delegating to streamTaskLogs()
ğŸ“º [WORKITEM] streamTaskLogs() called for task [query-abc123]
âš ï¸  [WORKITEM] No peon lifecycle available for task [query-abc123] - task may not have started yet
```

**Cause:** Task is queued but hasn't started running yet.

**Fix:** Wait a few seconds and try again. Check task status with:
```bash
curl "http://overlord:8090/druid/indexer/v1/task/${TASK_ID}/status"
```

---

### Scenario 3: Task Not in RUNNING State

**Logs:**
```
ğŸ“º [LIFECYCLE] streamLogs() called for task [query-abc123]
ğŸ“º [LIFECYCLE] Current task state: PENDING
âš ï¸  [LIFECYCLE] Task [query-abc123] is not in RUNNING state (state=PENDING), cannot stream logs
```

**Cause:** Task hasn't transitioned to RUNNING state yet.

**What to check:**
1. Is the pod starting up?
   ```bash
   kubectl get pods -l job-name=query-abc123
   ```

2. Look for state transition logs:
   ```bash
   grep "Transitioning task.*RUNNING" /logs/druid/overlord-*.log
   ```

**Expected state transition log:**
```
ğŸ”„ [LIFECYCLE] Transitioning task [query-abc123] to RUNNING state
âœ… [LIFECYCLE] Task [query-abc123] now in RUNNING state - logs should be streamable
```

---

### Scenario 4: Kubernetes API Failure

**Logs:**
```
ğŸ“º [K8S-CLIENT] getPeonLogWatcher() called for task [query-abc123]
ğŸ“º [K8S-CLIENT] Namespace: default, Container: main
ğŸ“º [K8S-CLIENT] Calling Kubernetes API .watchLog() for job [query-abc123]
âŒ [K8S-CLIENT] Error watching logs from task [query-abc123] (job: query-abc123): Pod not found
```

**Possible causes:**
1. Pod was terminated too quickly
2. Kubernetes API server is unreachable
3. Namespace or job name is incorrect
4. Container name is wrong

**Debugging:**
```bash
# Check if pod exists
kubectl get pods -l job-name=query-abc123 -n default

# Check job status
kubectl get job query-abc123 -n default -o yaml

# Check container name (should be "main")
kubectl get pod <pod-name> -o jsonpath='{.spec.containers[*].name}'
```

---

### Scenario 5: LogWatch is Null

**Logs:**
```
ğŸ“º [K8S-CLIENT] Calling Kubernetes API .watchLog() for job [query-abc123]
âš ï¸  [K8S-CLIENT] Kubernetes API returned null LogWatch for job [query-abc123]
```

**Cause:** Kubernetes client library returned null (unusual but possible).

**What to check:**
1. Kubernetes version compatibility
2. fabric8 client library version
3. Network issues between Overlord and K8s API server

---

## ğŸ§ª Testing Script

Use this script to test the complete flow:

```bash
#!/bin/bash
# test_live_logs_with_diagnostics.sh

echo "ğŸš€ Submitting test task..."
RESPONSE=$(curl -s -X POST http://prodft30-broker0.druid.singular.net:8082/druid/v2/sql/task \
  -H 'Content-Type: application/json' \
  -d '{
    "query": "INSERT INTO test_live_logs SELECT __time, country FROM buffer_tracker_stats_1728 WHERE __time >= TIMESTAMP '\''2025-08-01'\'' LIMIT 10000 PARTITIONED BY ALL",
    "context": {
      "tags": {"userProvidedTag": "medium"},
      "maxNumTasks": 2
    }
  }')

TASK_ID=$(echo $RESPONSE | jq -r '.taskId')
echo "âœ… Task submitted: $TASK_ID"
echo ""

echo "â³ Waiting 5 seconds for task to start..."
sleep 5
echo ""

echo "ğŸ“Š Checking task status..."
curl -s "http://prodft30-overlord0.druid.singular.net:8090/druid/indexer/v1/task/${TASK_ID}/status" | jq .status
echo ""

echo "ğŸ” Checking diagnostic logs in Overlord..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
ssh ubuntu@prodft30-overlord0 "sudo grep '${TASK_ID}' /logs/druid/overlord-stdout---supervisor-*.log | grep -E 'ğŸ“º|ğŸ“Š|âœ…|âš ï¸|âŒ' | tail -30"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

echo "ğŸ“º Attempting to stream logs..."
curl -s "http://prodft30-overlord0.druid.singular.net:8090/druid/indexer/v1/task/${TASK_ID}/log" | head -20
echo ""

echo "ğŸ” Final diagnostic check..."
ssh ubuntu@prodft30-overlord0 "sudo grep '${TASK_ID}' /logs/druid/overlord-stdout---supervisor-*.log | grep -E 'ğŸ“º|ğŸ“Š|âœ…|âš ï¸|âŒ' | tail -10"
```

---

## ğŸ“‹ Diagnostic Checklist

When logs don't stream, check in this order:

### âœ… Step 1: Verify Task Exists
```bash
# Look for this log
grep "ğŸ“º \[STREAM\] API request to stream logs" /logs/druid/overlord-*.log | grep ${TASK_ID}
```

**Expected:** Should see the API request logged.

**If missing:** Task might not exist or request didn't reach Overlord.

---

### âœ… Step 2: Verify Work Item Exists
```bash
# Look for this log
grep "ğŸ“º \[STREAM\] Found work item" /logs/druid/overlord-*.log | grep ${TASK_ID}
```

**Expected:** Should see "Found work item for task [...]"

**If see "No work item found":** Task hasn't been submitted to this runner.

---

### âœ… Step 3: Verify Peon Lifecycle Exists
```bash
# Look for this log
grep "ğŸ“º \[WORKITEM\] Peon lifecycle exists" /logs/druid/overlord-*.log | grep ${TASK_ID}
```

**Expected:** Should see "Peon lifecycle exists for task [...]"

**If see "No peon lifecycle available":** Task hasn't started yet. Wait and retry.

---

### âœ… Step 4: Verify Task is RUNNING
```bash
# Look for state transition
grep "âœ… \[LIFECYCLE\] Task.*now in RUNNING state" /logs/druid/overlord-*.log | grep ${TASK_ID}
```

**Expected:** Should see state transition to RUNNING.

**If task is PENDING:** Wait for pod to start.

**If task is STOPPED:** Task already finished.

---

### âœ… Step 5: Verify Kubernetes API Call
```bash
# Look for K8s client logs
grep "ğŸ“º \[K8S-CLIENT\] getPeonLogWatcher" /logs/druid/overlord-*.log | grep ${TASK_ID}
```

**Expected:** Should see Kubernetes API call.

**Check for:**
- âœ… "Successfully created LogWatch" = Working!
- âš ï¸ "returned null LogWatch" = K8s issue
- âŒ "Error watching logs" = Check exception details

---

## ğŸ“ Understanding State Flow

### Task Lifecycle States

```
NOT_STARTED â†’ PENDING â†’ RUNNING â†’ STOPPED
     â†“           â†“         â†“         â†“
  Can't stream Can't stream âœ… CAN STREAM Can't stream
```

**State transitions logged:**
```
ğŸ“Š [LIFECYCLE] Current state before join: PENDING
ğŸ”„ [LIFECYCLE] Transitioning task [query-abc123] to RUNNING state
âœ… [LIFECYCLE] Task [query-abc123] now in RUNNING state - logs should be streamable
```

**Key insight:** Logs can ONLY be streamed when state is RUNNING.

---

## ğŸ”§ Quick Debugging Commands

### Check All Streaming Attempts
```bash
sudo grep "ğŸ“º \[STREAM\] API request" /logs/druid/overlord-*.log | tail -20
```

### Check Recent Successes
```bash
sudo grep "âœ… \[STREAM\] Successfully obtained log stream" /logs/druid/overlord-*.log | tail -10
```

### Check Recent Failures
```bash
sudo grep "âš ï¸  \[STREAM\]\|âŒ \[K8S-CLIENT\]" /logs/druid/overlord-*.log | tail -20
```

### Full Trace for a Specific Task
```bash
TASK_ID="query-abc123"
sudo grep "${TASK_ID}" /logs/druid/overlord-*.log | grep -E "ğŸ“º|ğŸ“Š|âœ…|âš ï¸|âŒ"
```

---

## ğŸ“ˆ Performance Monitoring

### Count Streaming Requests
```bash
# Total requests
sudo grep "ğŸ“º \[STREAM\] API request" /logs/druid/overlord-*.log | wc -l

# Successful streams
sudo grep "âœ… \[STREAM\] Successfully obtained" /logs/druid/overlord-*.log | wc -l

# Failed streams
sudo grep "âš ï¸  \[STREAM\] No log stream available" /logs/druid/overlord-*.log | wc -l
```

### Calculate Success Rate
```bash
TOTAL=$(sudo grep "ğŸ“º \[STREAM\] API request" /logs/druid/overlord-*.log | wc -l)
SUCCESS=$(sudo grep "âœ… \[STREAM\] Successfully obtained" /logs/druid/overlord-*.log | wc -l)
echo "Success rate: $((SUCCESS * 100 / TOTAL))%"
```

---

## ğŸ¯ Expected Behavior After Fix

### Before Fix (Buggy)
- âš ï¸ No logs during execution
- âœ… Logs only after completion

### After Fix (Working)
- âœ… Logs stream live during execution
- âœ… Logs continue after completion (from S3)

---

## ğŸ“ Summary

**Log Flow Markers:**
1. `ğŸ“º [STREAM]` - Entry point
2. `ğŸ“º [WORKITEM]` - Work item layer
3. `ğŸ“º [LIFECYCLE]` - Lifecycle state checks
4. `ğŸ“º [K8S-CLIENT]` - Kubernetes API
5. `âœ…` - Success at each layer
6. `âš ï¸` - Warnings (expected failures)
7. `âŒ` - Errors (unexpected failures)

**Key Success Indicator:**
```
âœ… [STREAM] Successfully obtained log stream for task [...]
```

**If you see this, live streaming is working!** ğŸ‰

---

**Created:** December 2024  
**Purpose:** Diagnose live log streaming for Kubernetes tasks  
**Status:** Comprehensive logging added to all layers

