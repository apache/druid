---
layout: doc_page
---

# S3-compatible

Make sure to [include](../../operations/including-extensions.html) `druid-s3-extensions` as an extension.

## Deep Storage

S3-compatible deep storage is basically either S3 or something like Google Storage which exposes the same API as S3.

### Configuration

|Property|Possible Values|Description|Default|
|--------|---------------|-----------|-------|
|`druid.s3.accessKey`||S3 access key.|Must be set.|
|`druid.s3.secretKey`||S3 secret key.|Must be set.|
|`druid.storage.bucket`||Bucket to store in.|Must be set.|
|`druid.storage.baseKey`||Base key prefix to use, i.e. what directory.|Must be set.|
|`druid.storage.storageDirectory`||Directory for storing segments.|Must be set.|


Example conf:
```json
## s3
druid.s3.accessKey=<YOURACCESSKEY TO ACCESS S3 BUCKET>
druid.s3.secretKey=<YOURSECRETKEY TO ACCESS S3 BUCKET>
druid.storage.bucket=<BUCKETNAME>
druid.storage.baseKey=<PATH IN BUCKET FOR DEEPSTORAGE>
druid.storage.storageDirectory=<BUCKETNAME>/<PATH IN BUCKET FOR DEEPSTORAGE>
```

## StaticS3Firehose

This firehose ingests events from a predefined list of S3 objects.

Sample spec:

```json
"firehose" : {
    "type" : "static-s3",
    "uris": ["s3://foo/bar/file.gz", "s3://bar/foo/file2.gz"]
}
```

This firehose provides caching and prefetching features. In IndexTask, a firehose can be read twice if intervals or
shardSpecs are not specified, and, in this case, caching can be useful. Prefetching is preferred when direct scan of objects is slow.

|property|description|default|required?|
|--------|-----------|-------|---------|
|type|This should be `static-s3`.|N/A|yes|
|uris|JSON array of URIs where s3 files to be ingested are located.|N/A|`uris` or `prefixes` must be set|
|prefixes|JSON array of URI prefixes for the locations of s3 files to be ingested.|N/A|`uris` or `prefixes` must be set|
|maxCacheCapacityBytes|Maximum size of the cache space in bytes. 0 means disabling cache. Cached files are not removed until the ingestion task completes.|1073741824|no|
|maxFetchCapacityBytes|Maximum size of the fetch space in bytes. 0 means disabling prefetch. Prefetched files are removed immediately once they are read.|1073741824|no|
|prefetchTriggerBytes|Threshold to trigger prefetching s3 objects.|maxFetchCapacityBytes / 2|no|
|fetchTimeout|Timeout for fetching an s3 object.|60000|no|
|maxFetchRetry|Maximum retry for fetching an s3 object.|3|no|

## StaticHadoopIndexingSpec

This indexing spec can be used together with the S3 configuration

```json
{
    "type": "index_hadoop",
    "spec": {
        "ioConfig": {
            "type": "hadoop",
            "inputSpec": {
                "type": "static",
                "paths": "s3n://<YOUR S3 BUCKETNAME>/data/wikiticker-2015-09-12-sampled.json.gz"
            }
        },
        "tuningConfig": {
            "type": "hadoop",
            "jobProperties": {
                "fs.s3.awsAccessKeyId": "<YOURACCESSKEY TO ACCESS S3 BUCKET>",
                "fs.s3.awsSecretAccessKey": "<YOURSECRETKEY TO ACCESS S3 BUCKET>",
                "fs.s3.impl": "org.apache.hadoop.fs.s3native.NativeS3FileSystem",
                "fs.s3n.awsAccessKeyId": "<YOURACCESSKEY TO ACCESS S3 BUCKET>",
                "fs.s3n.awsSecretAccessKey": "<YOURSECRETKEY TO ACCESS S3 BUCKET>",
                "fs.s3n.impl": "org.apache.hadoop.fs.s3native.NativeS3FileSystem",
                "io.compression.codecs": "org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec"
            }
        },
        "dataSchema": {
            "dataSource": "wikiticker",
            "granularitySpec": {
                "type": "uniform",
                "segmentGranularity": "day",
                "queryGranularity": "none",
                "intervals": ["2015-09-12/2015-09-13"]
            },
            "parser": {
                "type": "string",
                "parseSpec": {
                    "format": "json",
                    "dimensionsSpec": {
                        "dimensions": [
                            "channel",
                            "cityName",
                            "comment",
                            "countryIsoCode",
                            "countryName",
                            "isAnonymous",
                            "isMinor",
                            "isNew",
                            "isRobot",
                            "isUnpatrolled",
                            "metroCode",
                            "namespace",
                            "page",
                            "regionIsoCode",
                            "regionName",
                            "user"
                        ]
                    },
                    "timestampSpec": {
                        "format": "auto",
                        "column": "time"
                    }
                }
            },
            "metricsSpec": [{
                    "name": "count",
                    "type": "count"
                },
                {
                    "name": "added",
                    "type": "longSum",
                    "fieldName": "added"
                },
                {
                    "name": "deleted",
                    "type": "longSum",
                    "fieldName": "deleted"
                },
                {
                    "name": "delta",
                    "type": "longSum",
                    "fieldName": "delta"
                },
                {
                    "name": "user_unique",
                    "type": "hyperUnique",
                    "fieldName": "user"
                }
            ]
        }
    }
}
```